{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA 3D Validation Features Extraction\n",
    "\n",
    "This notebook extracts all three types of features for RNA validation data:\n",
    "1. Thermodynamic features from RNA sequences\n",
    "2. Pseudodihedral angle features from 3D coordinates\n",
    "3. Mutual Information features from Multiple Sequence Alignments (MSAs)\n",
    "\n",
    "This notebook works with validation data that includes 3D structural information.\n",
    "\n",
    "## Dependencies\n",
    "- ViennaRNA (for thermodynamic features)\n",
    "- NumPy/SciPy/Pandas (core data processing)\n",
    "- Memory monitoring tools from src.analysis.memory_monitor\n",
    "- Feature extraction functions from src.analysis modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViennaRNA module imported successfully (version: 2.6.4)\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import psutil\n",
    "\n",
    "# Ensure the parent directory is in the path so we can import our module\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "# Import feature extraction modules\n",
    "from src.analysis.thermodynamic_analysis import extract_thermodynamic_features\n",
    "from src.analysis.dihedral_analysis import extract_dihedral_features\n",
    "from src.analysis.mutual_information import calculate_mutual_information, convert_mi_to_evolutionary_features\n",
    "from src.data.extract_features_simple import save_features_npz\n",
    "\n",
    "# Import memory monitoring utilities\n",
    "from src.analysis.memory_monitor import MemoryTracker, log_memory_usage, plot_memory_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "# Define paths and parameters for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relative paths\n",
    "DATA_DIR = Path(\"../data\")\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "# Output directories for each feature type\n",
    "THERMO_DIR = PROCESSED_DIR / \"thermo_features\"\n",
    "DIHEDRAL_DIR = PROCESSED_DIR / \"dihedral_features\"\n",
    "MI_DIR = PROCESSED_DIR / \"mi_features\"\n",
    "MEMORY_PLOTS_DIR = PROCESSED_DIR / \"memory_plots\"\n",
    "\n",
    "# Make sure all directories exist\n",
    "for directory in [RAW_DIR, PROCESSED_DIR, THERMO_DIR, DIHEDRAL_DIR, MI_DIR, MEMORY_PLOTS_DIR]:\n",
    "    directory.mkdir(exist_ok=True, parents=True)\n",
    "            \n",
    "# Parameters\n",
    "LIMIT = 5  # Limit for testing; set to None to process all data\n",
    "VERBOSE = True  # Whether to print detailed progress\n",
    "\n",
    "# Auto-detect if running on Kaggle\n",
    "KAGGLE_MODE = os.environ.get('KAGGLE_KERNEL_RUN_TYPE') is not None\n",
    "if KAGGLE_MODE:\n",
    "    print(\"Running in Kaggle environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "\n",
    "# Define utility functions for loading data and extracting features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rna_data(csv_path):\n",
    "    \"\"\"\n",
    "    Load RNA data from CSV file.\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to CSV file containing RNA data\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with RNA data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"Loaded {len(df)} entries from {csv_path}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_unique_target_ids(df, id_col=\"ID\"):\n",
    "    \"\"\"\n",
    "    Extract unique target IDs from dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with RNA data\n",
    "        id_col: Column containing IDs\n",
    "        \n",
    "    Returns:\n",
    "        List of unique target IDs\n",
    "    \"\"\"\n",
    "    # Extract target IDs (format: TARGET_ID_RESIDUE_NUM)\n",
    "    target_ids = []\n",
    "    for id_str in df[id_col]:\n",
    "        # Split the ID string and get the target ID part\n",
    "        parts = id_str.split('_')\n",
    "        if len(parts) >= 2:\n",
    "            target_id = f\"{parts[0]}_{parts[1]}\"  # Take the first two parts (e.g., \"1SCL_A\")\n",
    "            target_ids.append(target_id)\n",
    "    \n",
    "    # Get unique target IDs\n",
    "    unique_targets = sorted(list(set(target_ids)))\n",
    "    print(f\"Found {len(unique_targets)} unique target IDs\")\n",
    "    return unique_targets\n",
    "\n",
    "def load_structure_data(target_id, data_dir=RAW_DIR):\n",
    "    \"\"\"\n",
    "    Load structure data for a given target from labels CSV.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        data_dir: Directory containing data\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with structure coordinates or None if not found\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    # Extract base ID without residue number\n",
    "    parts = target_id.split('_')\n",
    "    base_id = parts[0]\n",
    "    \n",
    "    # Define possible label files\n",
    "    label_files = [\n",
    "        data_dir / \"validation_labels.csv\",\n",
    "        data_dir / \"test_labels.csv\"\n",
    "    ]\n",
    "    \n",
    "    for label_file in label_files:\n",
    "        if label_file.exists():\n",
    "            try:\n",
    "                print(f\"Looking for structure data for {target_id} in {label_file}\")\n",
    "                # Read the entire CSV file\n",
    "                all_data = pd.read_csv(label_file)\n",
    "                \n",
    "                # Method 1: Try exact match\n",
    "                if \"ID\" in all_data.columns:\n",
    "                    target_data = all_data[all_data[\"ID\"] == target_id]\n",
    "                    if len(target_data) > 0:\n",
    "                        print(f\"Found {len(target_data)} residues for {target_id} (exact match)\")\n",
    "                        return target_data\n",
    "                \n",
    "                # Method 2: Try matching by base ID\n",
    "                if \"ID\" in all_data.columns:\n",
    "                    # Look for rows with this base ID\n",
    "                    target_data = all_data[all_data[\"ID\"].str.startswith(f\"{base_id}_\")]\n",
    "                    if len(target_data) > 0:\n",
    "                        print(f\"Found {len(target_data)} residues with base ID {base_id}\")\n",
    "                        return target_data\n",
    "                \n",
    "                # Method 3: If we have a chain ID in the target (e.g., R1107_A_1)\n",
    "                if len(parts) >= 3 and parts[-1].isdigit():\n",
    "                    # Try base_id + chain\n",
    "                    base_with_chain = f\"{parts[0]}_{parts[1]}\"\n",
    "                    target_data = all_data[all_data[\"ID\"].str.startswith(base_with_chain)]\n",
    "                    if len(target_data) > 0:\n",
    "                        print(f\"Found {len(target_data)} residues with base+chain {base_with_chain}\")\n",
    "                        return target_data\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading from {label_file}: {e}\")\n",
    "    \n",
    "    print(f\"Could not find structure data for {target_id} in any labels file\")\n",
    "    return None\n",
    "\n",
    "def load_msa_data(target_id, data_dir=RAW_DIR):\n",
    "    \"\"\"\n",
    "    Load MSA data for a given target.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        data_dir: Directory containing MSA data\n",
    "        \n",
    "    Returns:\n",
    "        List of MSA sequences or None if not found\n",
    "    \"\"\"\n",
    "    # Try to find the MSA file\n",
    "    msa_paths = [\n",
    "        data_dir / \"MSA\" / f\"{target_id}.MSA.fasta\",\n",
    "        data_dir / f\"{target_id}.MSA.fasta\",\n",
    "        data_dir / \"alignments\" / f\"{target_id}.MSA.fasta\"\n",
    "    ]\n",
    "    \n",
    "    for path in msa_paths:\n",
    "        if path.exists():\n",
    "            print(f\"Loading MSA data from {path}\")\n",
    "            try:\n",
    "                # Parse FASTA file\n",
    "                sequences = []\n",
    "                current_seq = \"\"\n",
    "                \n",
    "                with open(path, 'r') as f:\n",
    "                    for line in f:\n",
    "                        line = line.strip()\n",
    "                        if line.startswith('>'):\n",
    "                            if current_seq:\n",
    "                                sequences.append(current_seq)\n",
    "                                current_seq = \"\"\n",
    "                        else:\n",
    "                            current_seq += line\n",
    "                            \n",
    "                    # Add the last sequence\n",
    "                    if current_seq:\n",
    "                        sequences.append(current_seq)\n",
    "                \n",
    "                print(f\"Loaded {len(sequences)} sequences from MSA\")\n",
    "                return sequences\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading MSA data: {e}\")\n",
    "                return None\n",
    "    \n",
    "    print(f\"Could not find MSA data for {target_id}\")\n",
    "    return None\n",
    "\n",
    "def get_sequence_for_target(target_id, data_dir=RAW_DIR):\n",
    "    \"\"\"\n",
    "    Get RNA sequence for a target ID from the sequence file.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID (e.g., \"R1107_A\")\n",
    "        data_dir: Directory containing sequence data\n",
    "        \n",
    "    Returns:\n",
    "        RNA sequence as string or None if not found\n",
    "    \"\"\"\n",
    "    # Try validation_sequences.csv first\n",
    "    validation_seq_path = data_dir / \"validation_sequences.csv\"\n",
    "    if validation_seq_path.exists():\n",
    "        try:\n",
    "            df = pd.read_csv(validation_seq_path)\n",
    "            # Try different possible column names for ID and sequence\n",
    "            id_cols = [\"target_id\", \"ID\", \"id\"]\n",
    "            seq_cols = [\"sequence\", \"Sequence\", \"seq\"]\n",
    "            \n",
    "            for id_col in id_cols:\n",
    "                if id_col in df.columns:\n",
    "                    for seq_col in seq_cols:\n",
    "                        if seq_col in df.columns:\n",
    "                            # Try exact match first\n",
    "                            target_row = df[df[id_col] == target_id]\n",
    "                            if len(target_row) > 0:\n",
    "                                sequence = target_row[seq_col].iloc[0]\n",
    "                                print(f\"Found sequence for {target_id} in validation_sequences.csv (exact match), length: {len(sequence)}\")\n",
    "                                return sequence\n",
    "                            \n",
    "                            # If exact match fails, try base target ID (remove residue number)\n",
    "                            base_id = target_id.split('_')[0]\n",
    "                            if '_' in target_id:\n",
    "                                # Try with just first component\n",
    "                                target_row = df[df[id_col] == base_id]\n",
    "                                if len(target_row) > 0:\n",
    "                                    sequence = target_row[seq_col].iloc[0]\n",
    "                                    print(f\"Found sequence for {target_id} using base ID {base_id}, length: {len(sequence)}\")\n",
    "                                    return sequence\n",
    "                                \n",
    "                                # Try with first two components (target and chain)\n",
    "                                parts = target_id.split('_')\n",
    "                                if len(parts) >= 2:\n",
    "                                    base_id_with_chain = f\"{parts[0]}_{parts[1]}\"\n",
    "                                    target_row = df[df[id_col] == base_id_with_chain]\n",
    "                                    if len(target_row) > 0:\n",
    "                                        sequence = target_row[seq_col].iloc[0]\n",
    "                                        print(f\"Found sequence for {target_id} using base+chain ID {base_id_with_chain}, length: {len(sequence)}\")\n",
    "                                        return sequence\n",
    "                            \n",
    "                            # Try partial matching\n",
    "                            for row_id in df[id_col]:\n",
    "                                if str(row_id) in target_id or target_id.startswith(str(row_id)):\n",
    "                                    target_row = df[df[id_col] == row_id]\n",
    "                                    sequence = target_row[seq_col].iloc[0]\n",
    "                                    print(f\"Found sequence for {target_id} using partial match with {row_id}, length: {len(sequence)}\")\n",
    "                                    return sequence\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sequence data from {validation_seq_path}: {e}\")\n",
    "    \n",
    "    # Continue with the rest of your existing function...\n",
    "    \n",
    "    # If not found in validation_sequences.csv, try other sequence files\n",
    "    sequence_paths = [\n",
    "        data_dir / \"sequences.csv\",\n",
    "        data_dir / \"test_sequences.csv\",\n",
    "        data_dir / \"validation_sequences.csv\"\n",
    "    ]\n",
    "    \n",
    "    for path in sequence_paths:\n",
    "        if path.exists():\n",
    "            try:\n",
    "                df = pd.read_csv(path)\n",
    "                \n",
    "                # Try different possible column names\n",
    "                id_cols = [\"target_id\", \"ID\", \"id\"]\n",
    "                seq_cols = [\"sequence\", \"Sequence\", \"seq\"]\n",
    "                \n",
    "                for id_col in id_cols:\n",
    "                    if id_col in df.columns:\n",
    "                        for seq_col in seq_cols:\n",
    "                            if seq_col in df.columns:\n",
    "                                # Find the target in the dataframe\n",
    "                                target_row = df[df[id_col] == target_id]\n",
    "                                if len(target_row) > 0:\n",
    "                                    sequence = target_row[seq_col].iloc[0]\n",
    "                                    print(f\"Found sequence for {target_id} in {path.name}, length: {len(sequence)}\")\n",
    "                                    return sequence\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading sequence data from {path}: {e}\")\n",
    "    \n",
    "    # As a last resort, try to extract it from MSA data\n",
    "    print(f\"Could not find sequence in CSV files, trying MSA files as a last resort\")\n",
    "    msa_sequences = load_msa_data(target_id, data_dir)\n",
    "    if msa_sequences and len(msa_sequences) > 0:\n",
    "        # The first sequence in the MSA is typically the target sequence\n",
    "        sequence = msa_sequences[0]\n",
    "        print(f\"Found sequence for {target_id} in MSA file, length: {len(sequence)}\")\n",
    "        return sequence\n",
    "    \n",
    "    print(f\"Could not find sequence for {target_id} in any file\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction Functions\n",
    "\n",
    "# Define functions for extracting each type of feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_thermo_features_for_target(target_id, sequence=None):\n",
    "    \"\"\"\n",
    "    Extract thermodynamic features for a given target.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        sequence: RNA sequence (optional, will be loaded if not provided)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with thermodynamic features or None if failed\n",
    "    \"\"\"\n",
    "    print(f\"Extracting thermodynamic features for {target_id}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Get sequence if not provided\n",
    "        if sequence is None:\n",
    "            sequence = get_sequence_for_target(target_id)\n",
    "            if sequence is None:\n",
    "                print(f\"Failed to get sequence for {target_id}\")\n",
    "                return None\n",
    "        \n",
    "        # Log initial memory usage\n",
    "        log_memory_usage(f\"Before thermo features for {target_id} (len={len(sequence)})\")\n",
    "        \n",
    "        # Calculate features with memory monitoring\n",
    "        print(f\"Calculating thermodynamic features for sequence of length {len(sequence)}\")\n",
    "        with MemoryTracker(f\"Thermodynamic features calculation for {target_id}\"):\n",
    "            features = extract_thermodynamic_features(sequence)\n",
    "        \n",
    "        # Save features\n",
    "        output_file = THERMO_DIR / f\"{target_id}_thermo_features.npz\"\n",
    "        features['target_id'] = target_id\n",
    "        features['sequence'] = sequence\n",
    "        \n",
    "        with MemoryTracker(\"Saving thermodynamic features\"):\n",
    "            save_features_npz(features, output_file)\n",
    "        \n",
    "        # Log final memory usage\n",
    "        log_memory_usage(f\"After thermo features for {target_id}\")\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Extracted thermodynamic features in {elapsed_time:.2f} seconds\")\n",
    "        return features\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting thermodynamic features for {target_id}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dihedral_features_for_all_structures(target_id, structure_data=None):\n",
    "    \"\"\"\n",
    "    Extract pseudodihedral angle features for all structure sets in validation data.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        structure_data: DataFrame with structure coordinates\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with dihedral features for all structures or None if failed\n",
    "    \"\"\"\n",
    "    print(f\"Extracting dihedral features for {target_id}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Get structure data if not provided\n",
    "        if structure_data is None:\n",
    "            structure_data = load_structure_data(target_id)\n",
    "            if structure_data is None:\n",
    "                print(f\"Failed to get structure data for {target_id}\")\n",
    "                return None\n",
    "        \n",
    "        # Check if we have at least 4 residues (required for dihedral angles)\n",
    "        if len(structure_data) < 4:\n",
    "            print(f\"Not enough residues ({len(structure_data)}) for {target_id}\")\n",
    "            return None\n",
    "        \n",
    "        # Find all coordinate sets (x_1, y_1, z_1), (x_2, y_2, z_2), etc.\n",
    "        x_cols = sorted([col for col in structure_data.columns if col.startswith('x_')])\n",
    "        y_cols = sorted([col for col in structure_data.columns if col.startswith('y_')])\n",
    "        z_cols = sorted([col for col in structure_data.columns if col.startswith('z_')])\n",
    "        \n",
    "        # Make sure we have matching coordinate sets\n",
    "        num_structures = len(x_cols)\n",
    "        if not (len(x_cols) == len(y_cols) == len(z_cols)):\n",
    "            print(f\"Mismatched coordinate columns: {len(x_cols)} x-cols, {len(y_cols)} y-cols, {len(z_cols)} z-cols\")\n",
    "            return None\n",
    "            \n",
    "        print(f\"Found {num_structures} structure sets for {target_id}\")\n",
    "        \n",
    "        # Output file path\n",
    "        output_file = DIHEDRAL_DIR / f\"{target_id}_dihedral_features.npz\"\n",
    "        \n",
    "        # Process each structure set\n",
    "        all_features = {\n",
    "            'target_id': target_id,\n",
    "            'num_structures': num_structures,\n",
    "            'structure_ids': list(range(1, num_structures + 1))\n",
    "        }\n",
    "        \n",
    "        for i in range(num_structures):\n",
    "            # Get column names for this structure\n",
    "            struct_idx = i + 1  # 1-based indexing in column names\n",
    "            x_col = f'x_{struct_idx}'\n",
    "            y_col = f'y_{struct_idx}'\n",
    "            z_col = f'z_{struct_idx}'\n",
    "            \n",
    "            # Skip if any column is missing\n",
    "            if not all(col in structure_data.columns for col in [x_col, y_col, z_col]):\n",
    "                print(f\"Skipping structure {struct_idx} due to missing coordinates\")\n",
    "                continue\n",
    "            \n",
    "            # Create a copy with renamed columns for compatibility with dihedral_analysis\n",
    "            struct_data = structure_data.copy()\n",
    "            \n",
    "            # Create 'resid' column if not present\n",
    "            if 'resid' not in struct_data.columns:\n",
    "                if 'residue' in struct_data.columns:\n",
    "                    struct_data['resid'] = struct_data['residue']\n",
    "                else:\n",
    "                    struct_data['resid'] = list(range(1, len(struct_data) + 1))\n",
    "            \n",
    "            # Rename coordinate columns to the standard names expected by dihedral_analysis\n",
    "            struct_data = struct_data.rename(columns={\n",
    "                x_col: 'x_1',\n",
    "                y_col: 'y_1',\n",
    "                z_col: 'z_1'\n",
    "            })\n",
    "            \n",
    "            print(f\"Processing structure {struct_idx}/{num_structures}\")\n",
    "            \n",
    "            # Calculate dihedral features for this structure\n",
    "            try:\n",
    "                dihedral_features = extract_dihedral_features(\n",
    "                    struct_data, \n",
    "                    output_file=None,  # Don't save individual structures\n",
    "                    include_raw_angles=True\n",
    "                )\n",
    "                \n",
    "                if dihedral_features is not None:\n",
    "                    # Add prefixed keys to identify this structure set\n",
    "                    for key, value in dihedral_features.items():\n",
    "                        all_features[f'struct_{struct_idx}_{key}'] = value\n",
    "                    \n",
    "                    print(f\"✅ Successfully processed structure {struct_idx}\")\n",
    "                else:\n",
    "                    print(f\"❌ Failed to extract features for structure {struct_idx}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing structure {struct_idx}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        # Check if we have at least one successful structure\n",
    "        successful_structs = sum(1 for key in all_features.keys() if key.startswith('struct_'))\n",
    "        if successful_structs == 0:\n",
    "            print(f\"No structures were successfully processed for {target_id}\")\n",
    "            return None\n",
    "            \n",
    "        # Save combined features\n",
    "        print(f\"Saving combined features for {successful_structs}/{num_structures} structures\")\n",
    "        save_features_npz(all_features, output_file)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Completed dihedral extraction in {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        return all_features\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in dihedral extraction for {target_id}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_dihedral_features_for_target(target_id, structure_data=None):\n",
    "    \"\"\"\n",
    "    Extract pseudodihedral angle features for a given target.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        structure_data: DataFrame with structure coordinates (optional)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with dihedral features or None if failed\n",
    "    \"\"\"\n",
    "    # Call the new function that handles multiple structures\n",
    "    return extract_dihedral_features_for_all_structures(target_id, structure_data)\n",
    "\n",
    "def extract_mi_features_for_target(target_id, structure_data=None, msa_sequences=None):\n",
    "    \"\"\"\n",
    "    Extract Mutual Information features for a given target.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        structure_data: DataFrame with structure data for correlation calculation (optional)\n",
    "        msa_sequences: List of MSA sequences (optional, will be loaded if not provided)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with MI features or None if failed\n",
    "    \"\"\"\n",
    "    print(f\"Extracting MI features for {target_id}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Get MSA sequences if not provided\n",
    "        if msa_sequences is None:\n",
    "            msa_sequences = load_msa_data(target_id)\n",
    "            if msa_sequences is None or len(msa_sequences) < 2:\n",
    "                print(f\"Failed to get MSA data for {target_id} or not enough sequences\")\n",
    "                return None\n",
    "        \n",
    "        # Get structure data if not provided (for correlation calculation)\n",
    "        if structure_data is None and target_id is not None:\n",
    "            structure_data = load_structure_data(target_id)\n",
    "        \n",
    "        # Log memory before MI calculation\n",
    "        sequence_length = len(msa_sequences[0]) if msa_sequences else 0\n",
    "        msa_size = len(msa_sequences) if msa_sequences else 0\n",
    "        log_memory_usage(f\"Before MI features for {target_id} (seq_len={sequence_length}, msa_size={msa_size})\")\n",
    "        \n",
    "        # Calculate MI (this may take some time for large MSAs)\n",
    "        print(f\"Calculating MI for {len(msa_sequences)} sequences\")\n",
    "        with MemoryTracker(f\"MI calculation for {target_id}\"):\n",
    "            mi_result = calculate_mutual_information(msa_sequences, verbose=VERBOSE)\n",
    "        \n",
    "        if mi_result is None:\n",
    "            print(f\"Failed to calculate MI for {target_id}\")\n",
    "            return None\n",
    "        \n",
    "        # Convert to evolutionary features\n",
    "        output_file = MI_DIR / f\"{target_id}_mi_features.npz\"\n",
    "        \n",
    "        # If we have structure data, use it for correlation calculation\n",
    "        if structure_data is not None:\n",
    "            print(f\"Converting MI to evolutionary features with structural correlation\")\n",
    "            with MemoryTracker(f\"MI-structure correlation for {target_id}\"):\n",
    "                features = convert_mi_to_evolutionary_features(mi_result, structure_data, output_file=output_file)\n",
    "        else:\n",
    "            print(f\"Converting MI to evolutionary features without structural correlation\")\n",
    "            features = mi_result\n",
    "            \n",
    "            # Save manually if convert_mi_to_evolutionary_features wasn't used\n",
    "            if output_file is not None:\n",
    "                with MemoryTracker(f\"Saving MI features for {target_id}\"):\n",
    "                    np.savez_compressed(output_file, **features)\n",
    "                print(f\"Saved MI features to {output_file}\")\n",
    "        \n",
    "        # Log memory after MI calculation\n",
    "        log_memory_usage(f\"After MI features for {target_id}\")\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Extracted MI features in {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        # Add target ID\n",
    "        features['target_id'] = target_id\n",
    "        return features\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting MI features for {target_id}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing\n",
    "\n",
    "Process multiple targets in batch mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_target(target_id, extract_thermo=True, extract_dihedral=True, extract_mi=True):\n",
    "    \"\"\"\n",
    "    Process a single target, extracting all requested feature types.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        extract_thermo: Whether to extract thermodynamic features\n",
    "        extract_dihedral: Whether to extract dihedral features\n",
    "        extract_mi: Whether to extract MI features\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with results for each feature type\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing target: {target_id}\")\n",
    "    results = {'target_id': target_id}\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load common data that might be used by multiple feature types\n",
    "    sequence = get_sequence_for_target(target_id) if extract_thermo else None\n",
    "    structure_data = load_structure_data(target_id) if extract_dihedral or extract_mi else None\n",
    "    msa_sequences = load_msa_data(target_id) if extract_mi else None\n",
    "    \n",
    "    # Extract thermodynamic features\n",
    "    if extract_thermo:\n",
    "        thermo_file = THERMO_DIR / f\"{target_id}_thermo_features.npz\"\n",
    "        \n",
    "        if thermo_file.exists():\n",
    "            print(f\"Thermodynamic features already exist for {target_id}\")\n",
    "            results['thermo'] = {'success': True, 'skipped': True}\n",
    "        else:\n",
    "            thermo_features = extract_thermo_features_for_target(target_id, sequence)\n",
    "            results['thermo'] = {'success': thermo_features is not None}\n",
    "    \n",
    "    # Extract dihedral features\n",
    "    if extract_dihedral:\n",
    "        dihedral_file = DIHEDRAL_DIR / f\"{target_id}_dihedral_features.npz\"\n",
    "        \n",
    "        if dihedral_file.exists():\n",
    "            print(f\"Dihedral features already exist for {target_id}\")\n",
    "            results['dihedral'] = {'success': True, 'skipped': True}\n",
    "        else:\n",
    "            dihedral_features = extract_dihedral_features_for_target(target_id, structure_data)\n",
    "            results['dihedral'] = {'success': dihedral_features is not None}\n",
    "    \n",
    "    # Extract MI features\n",
    "    if extract_mi:\n",
    "        mi_file = MI_DIR / f\"{target_id}_mi_features.npz\"\n",
    "        \n",
    "        if mi_file.exists():\n",
    "            print(f\"MI features already exist for {target_id}\")\n",
    "            results['mi'] = {'success': True, 'skipped': True}\n",
    "        else:\n",
    "            mi_features = extract_mi_features_for_target(target_id, structure_data, msa_sequences)\n",
    "            results['mi'] = {'success': mi_features is not None}\n",
    "    \n",
    "    # Calculate total time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    results['elapsed_time'] = elapsed_time\n",
    "    print(f\"Completed processing {target_id} in {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def batch_process_targets(target_ids, extract_thermo=True, extract_dihedral=True, extract_mi=True):\n",
    "    \"\"\"\n",
    "    Process multiple targets in batch mode.\n",
    "    \n",
    "    Args:\n",
    "        target_ids: List of target IDs\n",
    "        extract_thermo: Whether to extract thermodynamic features\n",
    "        extract_dihedral: Whether to extract dihedral features\n",
    "        extract_mi: Whether to extract MI features\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with results for each target\n",
    "    \"\"\"\n",
    "    print(f\"Starting batch processing for {len(target_ids)} targets\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    results = {}\n",
    "    for i, target_id in enumerate(target_ids):\n",
    "        print(f\"\\nProcessing target {i+1}/{len(target_ids)}: {target_id}\")\n",
    "        \n",
    "        # Process the target\n",
    "        target_results = process_target(\n",
    "            target_id, \n",
    "            extract_thermo=extract_thermo, \n",
    "            extract_dihedral=extract_dihedral, \n",
    "            extract_mi=extract_mi\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        results[target_id] = target_results\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    success_counts = {\n",
    "        'thermo': sum(1 for r in results.values() if 'thermo' in r and r['thermo']['success']),\n",
    "        'dihedral': sum(1 for r in results.values() if 'dihedral' in r and r['dihedral']['success']),\n",
    "        'mi': sum(1 for r in results.values() if 'mi' in r and r['mi']['success'])\n",
    "    }\n",
    "    \n",
    "    skipped_counts = {\n",
    "        'thermo': sum(1 for r in results.values() if 'thermo' in r and r['thermo'].get('skipped', False)),\n",
    "        'dihedral': sum(1 for r in results.values() if 'dihedral' in r and r['dihedral'].get('skipped', False)),\n",
    "        'mi': sum(1 for r in results.values() if 'mi' in r and r['mi'].get('skipped', False))\n",
    "    }\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nBatch processing complete!\")\n",
    "    print(f\"Total targets: {len(target_ids)}\")\n",
    "    print(f\"Total time: {total_time:.2f} seconds\")\n",
    "    \n",
    "    if extract_thermo:\n",
    "        print(f\"Thermodynamic features: {success_counts['thermo']} successful ({skipped_counts['thermo']} skipped)\")\n",
    "        \n",
    "    if extract_dihedral:\n",
    "        print(f\"Dihedral features: {success_counts['dihedral']} successful ({skipped_counts['dihedral']} skipped)\")\n",
    "        \n",
    "    if extract_mi:\n",
    "        print(f\"MI features: {success_counts['mi']} successful ({skipped_counts['mi']} skipped)\")\n",
    "    \n",
    "    # Save summary\n",
    "    summary = {\n",
    "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'total_targets': len(target_ids),\n",
    "        'total_time': total_time,\n",
    "        'success_counts': success_counts,\n",
    "        'skipped_counts': skipped_counts,\n",
    "        'target_results': results\n",
    "    }\n",
    "    \n",
    "    with open(PROCESSED_DIR / 'validation_processing_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial memory before loading data: 0.16 GB\n",
      "Loaded 2515 entries from ../data/raw/validation_labels.csv\n",
      "Loaded 12 entries from ../data/raw/validation_sequences.csv\n",
      "After loading validationing data: 0.16 GB\n",
      "Found 2515 unique target IDs\n",
      "Found sequences for 2515/2515 targets\n",
      "Limiting to first 5 targets for testing\n",
      "Starting Batch processing: 0.16 GB\n",
      "Starting batch processing for 5 targets\n",
      "\n",
      "Processing target 1/5: R1107_1\n",
      "\n",
      "Processing target: R1107_1\n",
      "Found sequence for R1107_1 using base ID R1107, length: 69\n",
      "Looking for structure data for R1107_1 in ../data/raw/validation_labels.csv\n",
      "Found 1 residues for R1107_1 (exact match)\n",
      "Could not find MSA data for R1107_1\n",
      "Extracting thermodynamic features for R1107_1\n",
      "Before thermo features for R1107_1 (len=69): 0.16 GB\n",
      "Calculating thermodynamic features for sequence of length 69\n",
      "Starting Thermodynamic features calculation for R1107_1: 0.16 GB\n",
      "Using ViennaRNA for thermodynamic calculations...\n",
      "Setting partition function scale factor (sfact) to 1.5\n",
      "Created fold_compound with custom model details\n",
      "Using enhanced MFE structure as fallback for BPP matrix\n",
      "Filled BPP matrix with 21 primary pairs and alternate configurations\n",
      "Raw ensemble energy: -23.69923973083496, MFE: -21.600000381469727\n",
      "Direct probability calculation: 0.03317093058302927\n",
      "Thermodynamic constraint violated: Ensemble energy (-23.69923973083496) < MFE (-21.600000381469727)\n",
      "Correcting ensemble energy to be slightly higher than MFE\n",
      "Thermodynamic validation detected and corrected inconsistencies\n",
      "Ensemble energy clamped from -23.69923973083496 to -21.590000381469725\n",
      "ViennaRNA calculation completed in 0.01 seconds\n",
      "Successfully calculated folding energy!\n",
      "  - mfe: -21.600000381469727\n",
      "  - mfe_structure: .........((((((((((....)))(((((((...((((.....)).))...)))))))..)))))))\n",
      "  - raw_ensemble_energy: -23.69923973083496\n",
      "  - ensemble_energy (clamped): -21.590000381469725\n",
      "  - probability: 0.03317093058302927\n",
      "Adding missing feature: mfe_structure\n",
      "Adding missing feature: structure\n",
      "Adding missing feature: prob_of_mfe\n",
      "Adding missing feature: base_pair_probs\n",
      "Adding missing feature: pairing_probs\n",
      "Finished Thermodynamic features calculation for R1107_1: 0.17 GB\n",
      "Thermodynamic features calculation for R1107_1 completed in 0.08 seconds\n",
      "Memory change: 0.00 GB (+0.00 GB)\n",
      "Starting Saving thermodynamic features: 0.17 GB\n",
      "Saved features to ../data/processed/thermo_features/R1107_1_thermo_features.npz\n",
      "Finished Saving thermodynamic features: 0.17 GB\n",
      "Saving thermodynamic features completed in 0.00 seconds\n",
      "Memory change: 0.00 GB (+0.00 GB)\n",
      "After thermo features for R1107_1: 0.17 GB\n",
      "Extracted thermodynamic features in 0.08 seconds\n",
      "Extracting dihedral features for R1107_1\n",
      "Not enough residues (1) for R1107_1\n",
      "Extracting MI features for R1107_1\n",
      "Could not find MSA data for R1107_1\n",
      "Failed to get MSA data for R1107_1 or not enough sequences\n",
      "Completed processing R1107_1 in 0.10 seconds\n",
      "\n",
      "Processing target 2/5: R1107_10\n",
      "\n",
      "Processing target: R1107_10\n",
      "Found sequence for R1107_10 using base ID R1107, length: 69\n",
      "Looking for structure data for R1107_10 in ../data/raw/validation_labels.csv\n",
      "Found 1 residues for R1107_10 (exact match)\n",
      "Could not find MSA data for R1107_10\n",
      "Extracting thermodynamic features for R1107_10\n",
      "Before thermo features for R1107_10 (len=69): 0.17 GB\n",
      "Calculating thermodynamic features for sequence of length 69\n",
      "Starting Thermodynamic features calculation for R1107_10: 0.17 GB\n",
      "Using ViennaRNA for thermodynamic calculations...\n",
      "Setting partition function scale factor (sfact) to 1.5\n",
      "Created fold_compound with custom model details\n",
      "Using enhanced MFE structure as fallback for BPP matrix\n",
      "Filled BPP matrix with 21 primary pairs and alternate configurations\n",
      "Raw ensemble energy: -23.69923973083496, MFE: -21.600000381469727\n",
      "Direct probability calculation: 0.03317093058302927\n",
      "Thermodynamic constraint violated: Ensemble energy (-23.69923973083496) < MFE (-21.600000381469727)\n",
      "Correcting ensemble energy to be slightly higher than MFE\n",
      "Thermodynamic validation detected and corrected inconsistencies\n",
      "Ensemble energy clamped from -23.69923973083496 to -21.590000381469725\n",
      "ViennaRNA calculation completed in 0.01 seconds\n",
      "Successfully calculated folding energy!\n",
      "  - mfe: -21.600000381469727\n",
      "  - mfe_structure: .........((((((((((....)))(((((((...((((.....)).))...)))))))..)))))))\n",
      "  - raw_ensemble_energy: -23.69923973083496\n",
      "  - ensemble_energy (clamped): -21.590000381469725\n",
      "  - probability: 0.03317093058302927\n",
      "Adding missing feature: mfe_structure\n",
      "Adding missing feature: structure\n",
      "Adding missing feature: prob_of_mfe\n",
      "Adding missing feature: base_pair_probs\n",
      "Adding missing feature: pairing_probs\n",
      "Finished Thermodynamic features calculation for R1107_10: 0.17 GB\n",
      "Thermodynamic features calculation for R1107_10 completed in 0.08 seconds\n",
      "Memory change: 0.00 GB (+0.00 GB)\n",
      "Starting Saving thermodynamic features: 0.17 GB\n",
      "Saved features to ../data/processed/thermo_features/R1107_10_thermo_features.npz\n",
      "Finished Saving thermodynamic features: 0.17 GB\n",
      "Saving thermodynamic features completed in 0.00 seconds\n",
      "Memory change: 0.00 GB (+0.00 GB)\n",
      "After thermo features for R1107_10: 0.17 GB\n",
      "Extracted thermodynamic features in 0.08 seconds\n",
      "Extracting dihedral features for R1107_10\n",
      "Not enough residues (1) for R1107_10\n",
      "Extracting MI features for R1107_10\n",
      "Could not find MSA data for R1107_10\n",
      "Failed to get MSA data for R1107_10 or not enough sequences\n",
      "Completed processing R1107_10 in 0.10 seconds\n",
      "\n",
      "Processing target 3/5: R1107_11\n",
      "\n",
      "Processing target: R1107_11\n",
      "Found sequence for R1107_11 using base ID R1107, length: 69\n",
      "Looking for structure data for R1107_11 in ../data/raw/validation_labels.csv\n",
      "Found 1 residues for R1107_11 (exact match)\n",
      "Could not find MSA data for R1107_11\n",
      "Extracting thermodynamic features for R1107_11\n",
      "Before thermo features for R1107_11 (len=69): 0.17 GB\n",
      "Calculating thermodynamic features for sequence of length 69\n",
      "Starting Thermodynamic features calculation for R1107_11: 0.17 GB\n",
      "Using ViennaRNA for thermodynamic calculations...\n",
      "Setting partition function scale factor (sfact) to 1.5\n",
      "Created fold_compound with custom model details\n",
      "Using enhanced MFE structure as fallback for BPP matrix\n",
      "Filled BPP matrix with 21 primary pairs and alternate configurations\n",
      "Raw ensemble energy: -23.69923973083496, MFE: -21.600000381469727\n",
      "Direct probability calculation: 0.03317093058302927\n",
      "Thermodynamic constraint violated: Ensemble energy (-23.69923973083496) < MFE (-21.600000381469727)\n",
      "Correcting ensemble energy to be slightly higher than MFE\n",
      "Thermodynamic validation detected and corrected inconsistencies\n",
      "Ensemble energy clamped from -23.69923973083496 to -21.590000381469725\n",
      "ViennaRNA calculation completed in 0.01 seconds\n",
      "Successfully calculated folding energy!\n",
      "  - mfe: -21.600000381469727\n",
      "  - mfe_structure: .........((((((((((....)))(((((((...((((.....)).))...)))))))..)))))))\n",
      "  - raw_ensemble_energy: -23.69923973083496\n",
      "  - ensemble_energy (clamped): -21.590000381469725\n",
      "  - probability: 0.03317093058302927\n",
      "Adding missing feature: mfe_structure\n",
      "Adding missing feature: structure\n",
      "Adding missing feature: prob_of_mfe\n",
      "Adding missing feature: base_pair_probs\n",
      "Adding missing feature: pairing_probs\n",
      "Finished Thermodynamic features calculation for R1107_11: 0.17 GB\n",
      "Thermodynamic features calculation for R1107_11 completed in 0.08 seconds\n",
      "Memory change: 0.00 GB (+0.00 GB)\n",
      "Starting Saving thermodynamic features: 0.17 GB\n",
      "Saved features to ../data/processed/thermo_features/R1107_11_thermo_features.npz\n",
      "Finished Saving thermodynamic features: 0.17 GB\n",
      "Saving thermodynamic features completed in 0.00 seconds\n",
      "Memory change: 0.00 GB (+0.00 GB)\n",
      "After thermo features for R1107_11: 0.17 GB\n",
      "Extracted thermodynamic features in 0.08 seconds\n",
      "Extracting dihedral features for R1107_11\n",
      "Not enough residues (1) for R1107_11\n",
      "Extracting MI features for R1107_11\n",
      "Could not find MSA data for R1107_11\n",
      "Failed to get MSA data for R1107_11 or not enough sequences\n",
      "Completed processing R1107_11 in 0.10 seconds\n",
      "\n",
      "Processing target 4/5: R1107_12\n",
      "\n",
      "Processing target: R1107_12\n",
      "Found sequence for R1107_12 using base ID R1107, length: 69\n",
      "Looking for structure data for R1107_12 in ../data/raw/validation_labels.csv\n",
      "Found 1 residues for R1107_12 (exact match)\n",
      "Could not find MSA data for R1107_12\n",
      "Extracting thermodynamic features for R1107_12\n",
      "Before thermo features for R1107_12 (len=69): 0.17 GB\n",
      "Calculating thermodynamic features for sequence of length 69\n",
      "Starting Thermodynamic features calculation for R1107_12: 0.17 GB\n",
      "Using ViennaRNA for thermodynamic calculations...\n",
      "Setting partition function scale factor (sfact) to 1.5\n",
      "Created fold_compound with custom model details\n",
      "Using enhanced MFE structure as fallback for BPP matrix\n",
      "Filled BPP matrix with 21 primary pairs and alternate configurations\n",
      "Raw ensemble energy: -23.69923973083496, MFE: -21.600000381469727\n",
      "Direct probability calculation: 0.03317093058302927\n",
      "Thermodynamic constraint violated: Ensemble energy (-23.69923973083496) < MFE (-21.600000381469727)\n",
      "Correcting ensemble energy to be slightly higher than MFE\n",
      "Thermodynamic validation detected and corrected inconsistencies\n",
      "Ensemble energy clamped from -23.69923973083496 to -21.590000381469725\n",
      "ViennaRNA calculation completed in 0.01 seconds\n",
      "Successfully calculated folding energy!\n",
      "  - mfe: -21.600000381469727\n",
      "  - mfe_structure: .........((((((((((....)))(((((((...((((.....)).))...)))))))..)))))))\n",
      "  - raw_ensemble_energy: -23.69923973083496\n",
      "  - ensemble_energy (clamped): -21.590000381469725\n",
      "  - probability: 0.03317093058302927\n",
      "Adding missing feature: mfe_structure\n",
      "Adding missing feature: structure\n",
      "Adding missing feature: prob_of_mfe\n",
      "Adding missing feature: base_pair_probs\n",
      "Adding missing feature: pairing_probs\n",
      "Finished Thermodynamic features calculation for R1107_12: 0.17 GB\n",
      "Thermodynamic features calculation for R1107_12 completed in 0.08 seconds\n",
      "Memory change: 0.00 GB (+0.00 GB)\n",
      "Starting Saving thermodynamic features: 0.17 GB\n",
      "Saved features to ../data/processed/thermo_features/R1107_12_thermo_features.npz\n",
      "Finished Saving thermodynamic features: 0.17 GB\n",
      "Saving thermodynamic features completed in 0.00 seconds\n",
      "Memory change: 0.00 GB (+0.00 GB)\n",
      "After thermo features for R1107_12: 0.17 GB\n",
      "Extracted thermodynamic features in 0.08 seconds\n",
      "Extracting dihedral features for R1107_12\n",
      "Not enough residues (1) for R1107_12\n",
      "Extracting MI features for R1107_12\n",
      "Could not find MSA data for R1107_12\n",
      "Failed to get MSA data for R1107_12 or not enough sequences\n",
      "Completed processing R1107_12 in 0.10 seconds\n",
      "\n",
      "Processing target 5/5: R1107_13\n",
      "\n",
      "Processing target: R1107_13\n",
      "Found sequence for R1107_13 using base ID R1107, length: 69\n",
      "Looking for structure data for R1107_13 in ../data/raw/validation_labels.csv\n",
      "Found 1 residues for R1107_13 (exact match)\n",
      "Could not find MSA data for R1107_13\n",
      "Extracting thermodynamic features for R1107_13\n",
      "Before thermo features for R1107_13 (len=69): 0.17 GB\n",
      "Calculating thermodynamic features for sequence of length 69\n",
      "Starting Thermodynamic features calculation for R1107_13: 0.17 GB\n",
      "Using ViennaRNA for thermodynamic calculations...\n",
      "Setting partition function scale factor (sfact) to 1.5\n",
      "Created fold_compound with custom model details\n",
      "Using enhanced MFE structure as fallback for BPP matrix\n",
      "Filled BPP matrix with 21 primary pairs and alternate configurations\n",
      "Raw ensemble energy: -23.69923973083496, MFE: -21.600000381469727\n",
      "Direct probability calculation: 0.03317093058302927\n",
      "Thermodynamic constraint violated: Ensemble energy (-23.69923973083496) < MFE (-21.600000381469727)\n",
      "Correcting ensemble energy to be slightly higher than MFE\n",
      "Thermodynamic validation detected and corrected inconsistencies\n",
      "Ensemble energy clamped from -23.69923973083496 to -21.590000381469725\n",
      "ViennaRNA calculation completed in 0.01 seconds\n",
      "Successfully calculated folding energy!\n",
      "  - mfe: -21.600000381469727\n",
      "  - mfe_structure: .........((((((((((....)))(((((((...((((.....)).))...)))))))..)))))))\n",
      "  - raw_ensemble_energy: -23.69923973083496\n",
      "  - ensemble_energy (clamped): -21.590000381469725\n",
      "  - probability: 0.03317093058302927\n",
      "Adding missing feature: mfe_structure\n",
      "Adding missing feature: structure\n",
      "Adding missing feature: prob_of_mfe\n",
      "Adding missing feature: base_pair_probs\n",
      "Adding missing feature: pairing_probs\n",
      "Finished Thermodynamic features calculation for R1107_13: 0.17 GB\n",
      "Thermodynamic features calculation for R1107_13 completed in 0.08 seconds\n",
      "Memory change: 0.00 GB (+0.00 GB)\n",
      "Starting Saving thermodynamic features: 0.17 GB\n",
      "Saved features to ../data/processed/thermo_features/R1107_13_thermo_features.npz\n",
      "Finished Saving thermodynamic features: 0.17 GB\n",
      "Saving thermodynamic features completed in 0.00 seconds\n",
      "Memory change: 0.00 GB (+0.00 GB)\n",
      "After thermo features for R1107_13: 0.17 GB\n",
      "Extracted thermodynamic features in 0.08 seconds\n",
      "Extracting dihedral features for R1107_13\n",
      "Not enough residues (1) for R1107_13\n",
      "Extracting MI features for R1107_13\n",
      "Could not find MSA data for R1107_13\n",
      "Failed to get MSA data for R1107_13 or not enough sequences\n",
      "Completed processing R1107_13 in 0.10 seconds\n",
      "\n",
      "Batch processing complete!\n",
      "Total targets: 5\n",
      "Total time: 0.49 seconds\n",
      "Thermodynamic features: 5 successful (0 skipped)\n",
      "Dihedral features: 0 successful (0 skipped)\n",
      "MI features: 0 successful (0 skipped)\n",
      "Finished Batch processing: 0.17 GB\n",
      "Batch processing completed in 0.49 seconds\n",
      "Memory change: 0.01 GB (+0.01 GB)\n",
      "\n",
      "Verifying processed features for compatibility...\n",
      "\n",
      "================================================================================\n",
      "Verifying RNA Feature Compatibility in: ../data/processed\n",
      "================================================================================\n",
      "\n",
      "Checking directory structure in ../data/processed...\n",
      "✅ Found required directory: dihedral_features\n",
      "✅ Found required directory: thermo_features\n",
      "✅ Found required directory: mi_features\n",
      "\n",
      "Found 15 targets with features\n",
      "Target IDs: 17RA_A, 17RA_A_mi, 1A1T_B, 1A1T_B_mi, 1A4T_A...\n",
      "\n",
      "Verifying features for target ID: 17RA_A\n",
      "Found 2/3 feature types:\n",
      "✅ Dihedral features: Dihedral features valid with shape (21, 4)\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (21, 21)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 17RA_A_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (21, 21)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A1T_B\n",
      "Found 2/3 feature types:\n",
      "✅ Dihedral features: Dihedral features valid with shape (20, 4)\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (20, 20)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A1T_B_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (20, 20)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A4T_A\n",
      "Found 2/3 feature types:\n",
      "✅ Dihedral features: Dihedral features valid with shape (15, 4)\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (15, 15)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A4T_A_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (15, 15)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A51_A\n",
      "Found 2/3 feature types:\n",
      "✅ Dihedral features: Dihedral features valid with shape (41, 4)\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (41, 41)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A51_A_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (41, 41)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A60_A\n",
      "Found 2/3 feature types:\n",
      "✅ Dihedral features: Dihedral features valid with shape (44, 4)\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (44, 44)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A60_A_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (44, 44)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1107_1\n",
      "Found 1/3 feature types:\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (69, 69)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1107_10\n",
      "Found 1/3 feature types:\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (69, 69)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1107_11\n",
      "Found 1/3 feature types:\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (69, 69)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1107_12\n",
      "Found 1/3 feature types:\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (69, 69)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1107_13\n",
      "Found 1/3 feature types:\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (69, 69)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "================================================================================\n",
      "Feature Verification Summary:\n",
      "- Total targets: 15\n",
      "- Valid targets: 15\n",
      "- Invalid targets: 0\n",
      "\n",
      "✅ All features are compatible with the data loader\n",
      "\n",
      "Final memory usage: 0.17 GB\n"
     ]
    }
   ],
   "source": [
    "# Log initial memory usage for the entire run\n",
    "log_memory_usage(\"Initial memory before loading data\")\n",
    "\n",
    "# Load validationing data - both labels and sequences\n",
    "validation_labels_file = RAW_DIR / \"validation_labels.csv\"\n",
    "validation_sequences_file = RAW_DIR / \"validation_sequences.csv\"\n",
    "\n",
    "validation_labels = load_rna_data(validation_labels_file)\n",
    "validation_sequences = load_rna_data(validation_sequences_file)\n",
    "\n",
    "log_memory_usage(\"After loading validationing data\")\n",
    "\n",
    "if validation_labels is None:\n",
    "    print(\"Error loading validationing labels. Please make sure validation_labels.csv exists.\")\n",
    "elif validation_sequences is None:\n",
    "    print(\"Error loading validationing sequences. Please make sure validation_sequences.csv exists.\")\n",
    "else:\n",
    "    # Get unique target IDs from labels\n",
    "    target_ids = get_unique_target_ids(validation_labels)\n",
    "    \n",
    "    # Verify sequences exist for target IDs\n",
    "    seq_id_col = next((col for col in [\"target_id\", \"ID\", \"id\"] if col in validation_sequences.columns), None)\n",
    "    if seq_id_col:\n",
    "        # Check if IDs in sequence file contain underscores (indicating chain/structure info)\n",
    "        sequence_ids = validation_sequences[seq_id_col].astype(str).tolist()\n",
    "        \n",
    "        if any(\"_\" in str(id_val) for id_val in sequence_ids):\n",
    "            # Sequence IDs have same format (with underscore), do direct comparison\n",
    "            available_targets = set(sequence_ids)\n",
    "            target_with_sequences = [tid for tid in target_ids if tid in available_targets]\n",
    "        else:\n",
    "            # Sequence IDs are in a different format, try to match the base part\n",
    "            # For example, match \"R1107\" from sequences file with \"R1107_A\" from labels\n",
    "            available_targets = set()\n",
    "            for seq_id in sequence_ids:\n",
    "                # Add the ID as is and also try adding common chain identifiers\n",
    "                available_targets.add(seq_id)\n",
    "                available_targets.add(f\"{seq_id}_A\")  # Common chain identifier\n",
    "            \n",
    "            target_with_sequences = [tid for tid in target_ids if tid in available_targets]\n",
    "            \n",
    "            # If still no matches, try more flexible matching\n",
    "            if not target_with_sequences:\n",
    "                # Try to match beginning of target ID with sequence ID\n",
    "                target_with_sequences = []\n",
    "                for tid in target_ids:\n",
    "                    for seq_id in sequence_ids:\n",
    "                        if seq_id in tid or tid.startswith(seq_id):\n",
    "                            target_with_sequences.append(tid)\n",
    "                            break\n",
    "        \n",
    "        missing_sequences = len(target_ids) - len(target_with_sequences)\n",
    "        \n",
    "        if missing_sequences > 0:\n",
    "            print(f\"Warning: {missing_sequences} targets do not have sequences in validation_sequences.csv\")\n",
    "        \n",
    "        print(f\"Found sequences for {len(target_with_sequences)}/{len(target_ids)} targets\")\n",
    "        target_ids = target_with_sequences\n",
    "    # Limit for testing\n",
    "    if LIMIT is not None and LIMIT < len(target_ids):\n",
    "        print(f\"Limiting to first {LIMIT} targets for testing\")\n",
    "        target_ids = target_ids[:LIMIT]\n",
    "    \n",
    "    # Process targets\n",
    "    with MemoryTracker(\"Batch processing\"):\n",
    "        results = batch_process_targets(\n",
    "            target_ids,\n",
    "            extract_thermo=True,\n",
    "            extract_dihedral=True,\n",
    "            extract_mi=True\n",
    "        )\n",
    "    \n",
    "    # Verify features\n",
    "    print(\"\\nVerifying processed features for compatibility...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    verification_script = Path(\"../scripts/verify_feature_compatibility.py\")\n",
    "    if verification_script.exists():\n",
    "        try:\n",
    "            # Run the script as a subprocess\n",
    "            cmd = [sys.executable, str(verification_script), str(PROCESSED_DIR), \"--verbose\"]\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "            \n",
    "            # Print the output\n",
    "            print(result.stdout)\n",
    "            \n",
    "            # Check for errors\n",
    "            if result.returncode != 0:\n",
    "                print(f\"Verification failed with exit code {result.returncode}\")\n",
    "                if result.stderr:\n",
    "                    print(f\"Error output: {result.stderr}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error running verification script: {e}\")\n",
    "    else:\n",
    "        print(f\"Warning: Feature verification script not found at {verification_script}\")\n",
    "    \n",
    "    # Plot memory usage\n",
    "    log_memory_usage(\"Final memory usage\")\n",
    "    #plot_memory_usage(output_file=MEMORY_PLOTS_DIR / \"validation_memory_usage.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dihedral extraction for validation target: R1107_1\n",
      "Looking for structure data for R1107_1 in ../data/raw/validation_labels.csv\n",
      "Found 1 residues for R1107_1 (exact match)\n",
      "Found 40 coordinate sets: x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30, x_31, x_32, x_33, x_34, x_35, x_36, x_37, x_38, x_39, x_40\n",
      "Extracting dihedral features for R1107_1\n",
      "Not enough residues (1) for R1107_1\n",
      "❌ Failed to extract dihedral features\n"
     ]
    }
   ],
   "source": [
    "def test_validation_dihedral_extraction():\n",
    "    \"\"\"Test dihedral extraction on a single validation target.\"\"\"\n",
    "    if not target_ids or len(target_ids) == 0:\n",
    "        print(\"No target IDs available to test\")\n",
    "        return\n",
    "    \n",
    "    test_target = target_ids[0]\n",
    "    print(f\"Testing dihedral extraction for validation target: {test_target}\")\n",
    "    \n",
    "    # Load structure data\n",
    "    structure_data = load_structure_data(test_target)\n",
    "    if structure_data is None:\n",
    "        print(f\"❌ Failed to load structure data for {test_target}\")\n",
    "        return\n",
    "    \n",
    "    # Count coordinate sets\n",
    "    x_cols = [col for col in structure_data.columns if col.startswith('x_')]\n",
    "    print(f\"Found {len(x_cols)} coordinate sets: {', '.join(x_cols)}\")\n",
    "    \n",
    "    # Extract dihedral features\n",
    "    features = extract_dihedral_features_for_target(test_target, structure_data)\n",
    "    \n",
    "    if features is not None:\n",
    "        print(f\"✅ Successfully extracted dihedral features\")\n",
    "        print(f\"Number of structures: {features.get('num_structures', 'Unknown')}\")\n",
    "        print(\"Feature keys:\")\n",
    "        for key in list(features.keys())[:10]:  # Show first 10 keys\n",
    "            print(f\"  - {key}\")\n",
    "        if len(features) > 10:\n",
    "            print(f\"  ... and {len(features) - 10} more\")\n",
    "    else:\n",
    "        print(f\"❌ Failed to extract dihedral features\")\n",
    "\n",
    "# Run the test on a single target before batch processing\n",
    "test_validation_dihedral_extraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader Compatibility Check\n",
    "\n",
    "Visualize and validate the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature verification script on ../data/processed\n",
      "\n",
      "================================================================================\n",
      "Verifying RNA Feature Compatibility in: ../data/processed\n",
      "================================================================================\n",
      "\n",
      "Checking directory structure in ../data/processed...\n",
      "✅ Found required directory: dihedral_features\n",
      "✅ Found required directory: thermo_features\n",
      "✅ Found required directory: mi_features\n",
      "\n",
      "Found 15 targets with features\n",
      "Target IDs: 17RA_A, 17RA_A_mi, 1A1T_B, 1A1T_B_mi, 1A4T_A...\n",
      "\n",
      "Verifying features for target ID: 17RA_A\n",
      "Found 2/3 feature types:\n",
      "✅ Dihedral features: Dihedral features valid with shape (21, 4)\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (21, 21)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 17RA_A_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (21, 21)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A1T_B\n",
      "Found 2/3 feature types:\n",
      "✅ Dihedral features: Dihedral features valid with shape (20, 4)\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (20, 20)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A1T_B_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (20, 20)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A4T_A\n",
      "Found 2/3 feature types:\n",
      "✅ Dihedral features: Dihedral features valid with shape (15, 4)\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (15, 15)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A4T_A_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (15, 15)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A51_A\n",
      "Found 2/3 feature types:\n",
      "✅ Dihedral features: Dihedral features valid with shape (41, 4)\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (41, 41)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A51_A_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (41, 41)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A60_A\n",
      "Found 2/3 feature types:\n",
      "✅ Dihedral features: Dihedral features valid with shape (44, 4)\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (44, 44)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A60_A_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (44, 44)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1107_1\n",
      "Found 1/3 feature types:\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (69, 69)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1107_10\n",
      "Found 1/3 feature types:\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (69, 69)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1107_11\n",
      "Found 1/3 feature types:\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (69, 69)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1107_12\n",
      "Found 1/3 feature types:\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (69, 69)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1107_13\n",
      "Found 1/3 feature types:\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (69, 69)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "================================================================================\n",
      "Feature Verification Summary:\n",
      "- Total targets: 15\n",
      "- Valid targets: 15\n",
      "- Invalid targets: 0\n",
      "\n",
      "✅ All features are compatible with the data loader\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the feature verification script on our extracted features\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def verify_features():\n",
    "    \"\"\"Run the feature verification script on the processed data directory.\"\"\"\n",
    "    verification_script = Path(\"../scripts/verify_feature_compatibility.py\")\n",
    "    \n",
    "    # Check if the script exists\n",
    "    if not verification_script.exists():\n",
    "        print(f\"Error: Verification script not found at {verification_script}\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"Running feature verification script on {PROCESSED_DIR}\")\n",
    "    try:\n",
    "        # Run the script as a subprocess\n",
    "        cmd = [sys.executable, str(verification_script), str(PROCESSED_DIR), \"--verbose\"]\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        \n",
    "        # Print the output\n",
    "        print(result.stdout)\n",
    "        \n",
    "        # Check for errors\n",
    "        if result.returncode != 0:\n",
    "            print(f\"Verification failed with exit code {result.returncode}\")\n",
    "            if result.stderr:\n",
    "                print(f\"Error output: {result.stderr}\")\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error running verification script: {e}\")\n",
    "        return False\n",
    "\n",
    "# Uncomment to run the verification when features are available\n",
    "compatibility_check = verify_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_structure_data(target_id, data_dir=RAW_DIR):\n",
    "    \"\"\"Debug helper to diagnose structure loading issues.\"\"\"\n",
    "    print(f\"\\n=== DEBUGGING STRUCTURE DATA FOR {target_id} ===\")\n",
    "    \n",
    "    # Try to load the data\n",
    "    structure_data = load_structure_data(target_id, data_dir)\n",
    "    \n",
    "    if structure_data is None:\n",
    "        print(\"❌ No structure data found!\")\n",
    "        \n",
    "        # Check what label files exist\n",
    "        label_files = [\n",
    "            data_dir / \"validation_labels.csv\",\n",
    "            data_dir / \"test_labels.csv\",\n",
    "            data_dir / \"train_labels.csv\" \n",
    "        ]\n",
    "        \n",
    "        for label_file in label_files:\n",
    "            if label_file.exists():\n",
    "                print(f\"📄 Found label file: {label_file}\")\n",
    "                \n",
    "                # Check structure of file\n",
    "                try:\n",
    "                    df = pd.read_csv(label_file)\n",
    "                    print(f\"  - Columns: {df.columns.tolist()}\")\n",
    "                    print(f\"  - Sample IDs: {df['ID'].head(3).tolist() if 'ID' in df.columns else 'No ID column'}\")\n",
    "                    \n",
    "                    # Check if target ID exists in any similar form\n",
    "                    base_id = target_id.split('_')[0]\n",
    "                    matches = df[df['ID'].str.contains(base_id, regex=False)] if 'ID' in df.columns else None\n",
    "                    if matches is not None and len(matches) > 0:\n",
    "                        print(f\"  - Found {len(matches)} rows containing '{base_id}'\")\n",
    "                        print(f\"  - Sample IDs: {matches['ID'].head(3).tolist()}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  - Error reading file: {e}\")\n",
    "    else:\n",
    "        print(f\"✅ Found {len(structure_data)} residues for {target_id}\")\n",
    "        print(f\"Columns: {structure_data.columns.tolist()}\")\n",
    "        \n",
    "        # Check for coordinate columns\n",
    "        x_cols = [col for col in structure_data.columns if col.startswith('x_')]\n",
    "        y_cols = [col for col in structure_data.columns if col.startswith('y_')]\n",
    "        z_cols = [col for col in structure_data.columns if col.startswith('z_')]\n",
    "        \n",
    "        print(f\"Coordinate columns:\")\n",
    "        print(f\"  - X columns: {x_cols}\")\n",
    "        print(f\"  - Y columns: {y_cols}\")\n",
    "        print(f\"  - Z columns: {z_cols}\")\n",
    "        \n",
    "        # Check if proper coordinate columns exist\n",
    "        if not (x_cols and y_cols and z_cols):\n",
    "            print(\"❌ Missing coordinate columns!\")\n",
    "            \n",
    "        # Print the first few rows for inspection\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(structure_data.head(2))\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    return structure_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rna3d-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
