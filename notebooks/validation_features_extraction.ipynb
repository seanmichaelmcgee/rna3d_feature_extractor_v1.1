{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA 3D Validation Features Extraction\n",
    "\n",
    "This notebook extracts all three types of features for RNA validation data:\n",
    "1. Thermodynamic features from RNA sequences\n",
    "2. Pseudodihedral angle features from 3D coordinates\n",
    "3. Mutual Information features from Multiple Sequence Alignments (MSAs)\n",
    "\n",
    "This notebook works with validation data that includes 3D structural information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Ensure the parent directory is in the path so we can import our modules\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import feature extraction modules\n",
    "from src.analysis.thermodynamic_analysis import extract_thermodynamic_features\n",
    "from src.analysis.dihedral_analysis import extract_dihedral_features\n",
    "from src.analysis.mutual_information import calculate_mutual_information, convert_mi_to_evolutionary_features\n",
    "from src.data.extract_features_simple import save_features_npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Define paths and parameters for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relative paths\n",
    "DATA_DIR = Path(\"../data\")\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "# Output directories for each feature type\n",
    "THERMO_DIR = PROCESSED_DIR / \"thermo_features\"\n",
    "DIHEDRAL_DIR = PROCESSED_DIR / \"dihedral_features\"\n",
    "MI_DIR = PROCESSED_DIR / \"mi_features\"\n",
    "\n",
    "# Make sure all directories exist\n",
    "for directory in [RAW_DIR, PROCESSED_DIR, THERMO_DIR, DIHEDRAL_DIR, MI_DIR]:\n",
    "    directory.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Parameters\n",
    "LIMIT = 5  # Limit for testing; set to None to process all data\n",
    "VERBOSE = True  # Whether to print detailed progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Define utility functions for loading data and extracting features."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def load_rna_data(csv_path):\\n    \\\"\\\"\\\"\\n    Load RNA data from CSV file.\\n    \\n    Args:\\n        csv_path: Path to CSV file containing RNA data\\n        \\n    Returns:\\n        DataFrame with RNA data\\n    \\\"\\\"\\\"\\n    try:\\n        df = pd.read_csv(csv_path)\\n        print(f\\\"Loaded {len(df)} entries from {csv_path}\\\")\\n        return df\\n    except Exception as e:\\n        print(f\\\"Error loading CSV file: {e}\\\")\\n        return None\\n\\ndef get_unique_target_ids(df, id_col=\\\"ID\\\"):\\n    \\\"\\\"\\\"\\n    Extract unique target IDs from dataframe.\\n    \\n    Args:\\n        df: DataFrame with RNA data\\n        id_col: Column containing IDs\\n        \\n    Returns:\\n        List of unique target IDs\\n    \\\"\\\"\\\"\\n    # Extract target IDs (format: TARGET_ID_RESIDUE_NUM)\\n    target_ids = []\\n    for id_str in df[id_col]:\\n        # Split the ID string and get the target ID part\\n        parts = id_str.split('_')\\n        if len(parts) >= 2:\\n            target_id = f\\\"{parts[0]}_{parts[1]}\\\"  # Take the first two parts (e.g., \\\"1SCL_A\\\")\\n            target_ids.append(target_id)\\n    \\n    # Get unique target IDs\\n    unique_targets = sorted(list(set(target_ids)))\\n    print(f\\\"Found {len(unique_targets)} unique target IDs\\\")\\n    return unique_targets\\n\\ndef load_structure_data(target_id, data_dir=RAW_DIR):\\n    \\\"\\\"\\\"\\n    Load structure data for a given target from labels CSV.\\n    \\n    Args:\\n        target_id: Target ID\\n        data_dir: Directory containing data\\n        \\n    Returns:\\n        DataFrame with structure coordinates or None if not found\\n    \\\"\\\"\\\"\\n    data_dir = Path(data_dir)\\n    \\n    # Define possible label files (train or validation)\\n    label_files = [\\n        data_dir / \\\"train_labels.csv\\\",\\n        data_dir / \\\"validation_labels.csv\\\"\\n    ]\\n    \\n    for label_file in label_files:\\n        if label_file.exists():\\n            try:\\n                print(f\\\"Looking for {target_id} in {label_file}\\\")\\n                # Read the entire CSV file\\n                all_data = pd.read_csv(label_file)\\n                \\n                # Filter rows for this target ID\\n                target_data = all_data[all_data[\\\"ID\\\"].str.startswith(f\\\"{target_id}_\\\")]\\n                \\n                if len(target_data) > 0:\\n                    print(f\\\"Found {len(target_data)} residues for {target_id}\\\")\\n                    return target_data\\n            except Exception as e:\\n                print(f\\\"Error loading from {label_file}: {e}\\\")\\n    \\n    print(f\\\"Could not find structure data for {target_id} in any labels file\\\")\\n    return None\\n\\ndef load_msa_data(target_id, data_dir=RAW_DIR):\\n    \\\"\\\"\\\"\\n    Load MSA data for a given target.\\n    \\n    Args:\\n        target_id: Target ID\\n        data_dir: Directory containing MSA data\\n        \\n    Returns:\\n        List of MSA sequences or None if not found\\n    \\\"\\\"\\\"\\n    # Define possible MSA directories and extensions\\n    msa_dirs = [\\n        data_dir / \\\"MSA\\\",\\n        data_dir,\\n        data_dir / \\\"alignments\\\",\\n        data_dir / \\\"validation\\\" / \\\"MSA\\\",\\n        data_dir / \\\"validation\\\",\\n        data_dir / \\\"validation\\\" / \\\"alignments\\\"\\n    ]\\n    \\n    extensions = [\\\".MSA.fasta\\\", \\\".fasta\\\", \\\".fa\\\", \\\".afa\\\", \\\".msa\\\"]\\n    \\n    # Try all combinations of directories and extensions\\n    for msa_dir in msa_dirs:\\n        if not msa_dir.exists():\\n            continue\\n            \\n        for ext in extensions:\\n            msa_path = msa_dir / f\\\"{target_id}{ext}\\\"\\n            if msa_path.exists():\\n                print(f\\\"Loading MSA data from {msa_path}\\\")\\n                try:\\n                    # Parse FASTA file\\n                    sequences = []\\n                    current_seq = \\\"\\\"\\n                    \\n                    with open(msa_path, 'r') as f:\\n                        for line in f:\\n                            line = line.strip()\\n                            if line.startswith('>'):\\n                                if current_seq:\\n                                    sequences.append(current_seq)\\n                                    current_seq = \\\"\\\"\\n                            else:\\n                                current_seq += line\\n                                \\n                        # Add the last sequence\\n                        if current_seq:\\n                            sequences.append(current_seq)\\n                    \\n                    print(f\\\"Loaded {len(sequences)} sequences from MSA\\\")\\n                    return sequences\\n                except Exception as e:\\n                    print(f\\\"Error loading MSA data: {e}\\\")\\n    \\n    # Fallback: try recursive search\\n    print(f\\\"MSA file not found in standard locations, trying recursive search...\\\")\\n    try:\\n        for msa_dir in [data_dir, data_dir / \\\"validation\\\"]:\\n            if not msa_dir.exists():\\n                continue\\n                \\n            for ext in extensions:\\n                pattern = f\\\"**/{target_id}{ext}\\\"\\n                matches = list(msa_dir.glob(pattern))\\n                if matches:\\n                    msa_path = matches[0]\\n                    print(f\\\"Found MSA via recursive search: {msa_path}\\\")\\n                    \\n                    # Parse the file\\n                    sequences = []\\n                    current_seq = \\\"\\\"\\n                    \\n                    with open(msa_path, 'r') as f:\\n                        for line in f:\\n                            line = line.strip()\\n                            if line.startswith('>'):\\n                                if current_seq:\\n                                    sequences.append(current_seq)\\n                                    current_seq = \\\"\\\"\\n                            else:\\n                                current_seq += line\\n                                \\n                        # Add the last sequence\\n                        if current_seq:\\n                            sequences.append(current_seq)\\n                    \\n                    print(f\\\"Loaded {len(sequences)} sequences from MSA\\\")\\n                    return sequences\\n    except Exception as e:\\n        print(f\\\"Error in recursive MSA search: {e}\\\")\\n    \\n    print(f\\\"Could not find MSA data for {target_id}\\\")\\n    return None\\n\\ndef get_sequence_for_target(target_id, data_dir=RAW_DIR):\\n    \\\"\\\"\\\"\\n    Get RNA sequence for a target ID from the sequence file.\\n    \\n    Args:\\n        target_id: Target ID\\n        data_dir: Directory containing sequence data\\n        \\n    Returns:\\n        RNA sequence as string or None if not found\\n    \\\"\\\"\\\"\\n    # Try different possible file locations\\n    sequence_paths = [\\n        data_dir / \\\"sequences.csv\\\",\\n        data_dir / \\\"train_sequences.csv\\\",\\n        data_dir / \\\"validation_sequences.csv\\\",\\n        data_dir / \\\"rna_sequences.csv\\\",\\n        data_dir / \\\"validation\\\" / \\\"sequences.csv\\\",\\n        data_dir / \\\"validation\\\" / \\\"validation_sequences.csv\\\"\\n    ]\\n    \\n    for path in sequence_paths:\\n        if path.exists():\\n            try:\\n                df = pd.read_csv(path)\\n                \\n                # Try different possible column names\\n                id_cols = [\\\"target_id\\\", \\\"ID\\\", \\\"id\\\"]\\n                seq_cols = [\\\"sequence\\\", \\\"Sequence\\\", \\\"seq\\\"]\\n                \\n                for id_col in id_cols:\\n                    if id_col in df.columns:\\n                        for seq_col in seq_cols:\\n                            if seq_col in df.columns:\\n                                # Find the target in the dataframe\\n                                target_row = df[df[id_col] == target_id]\\n                                if len(target_row) > 0:\\n                                    sequence = target_row[seq_col].iloc[0]\\n                                    return sequence\\n            except Exception as e:\\n                print(f\\\"Error loading sequence data from {path}: {e}\\\")\\n    \\n    # If we still haven't found the sequence, try to extract it from MSA data\\n    msa_sequences = load_msa_data(target_id, data_dir)\\n    if msa_sequences and len(msa_sequences) > 0:\\n        # The first sequence in the MSA is typically the target sequence\\n        return msa_sequences[0]\\n    \\n    print(f\\\"Could not find sequence for {target_id}\\\")\\n    return None"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Functions\n",
    "\n",
    "Define functions for extracting each type of feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_thermo_features_for_target(target_id, sequence=None):\n",
    "    \"\"\"\n",
    "    Extract thermodynamic features for a given target.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        sequence: RNA sequence (optional, will be loaded if not provided)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with thermodynamic features or None if failed\n",
    "    \"\"\"\n",
    "    print(f\"Extracting thermodynamic features for {target_id}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Get sequence if not provided\n",
    "        if sequence is None:\n",
    "            sequence = get_sequence_for_target(target_id)\n",
    "            if sequence is None:\n",
    "                print(f\"Failed to get sequence for {target_id}\")\n",
    "                return None\n",
    "        \n",
    "        # Calculate features\n",
    "        print(f\"Calculating thermodynamic features for sequence of length {len(sequence)}\")\n",
    "        features = extract_thermodynamic_features(sequence)\n",
    "        \n",
    "        # Save features\n",
    "        output_file = THERMO_DIR / f\"{target_id}_thermo_features.npz\"\n",
    "        features['target_id'] = target_id\n",
    "        features['sequence'] = sequence\n",
    "        \n",
    "        save_features_npz(features, output_file)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Extracted thermodynamic features in {elapsed_time:.2f} seconds\")\n",
    "        return features\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting thermodynamic features for {target_id}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def extract_dihedral_features_for_target(target_id, structure_data=None):\n",
    "    \"\"\"\n",
    "    Extract pseudodihedral angle features for a given target.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        structure_data: DataFrame with structure coordinates (optional, will be loaded if not provided)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with dihedral features or None if failed\n",
    "    \"\"\"\n",
    "    print(f\"Extracting dihedral features for {target_id}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Get structure data if not provided\n",
    "        if structure_data is None:\n",
    "            structure_data = load_structure_data(target_id)\n",
    "            if structure_data is None:\n",
    "                print(f\"Failed to get structure data for {target_id}\")\n",
    "                return None\n",
    "        \n",
    "        # Check if we have at least 4 residues (required for dihedral angles)\n",
    "        if len(structure_data) < 4:\n",
    "            print(f\"Not enough residues ({len(structure_data)}) for {target_id}, minimum 4 required for dihedral angles\")\n",
    "            return None\n",
    "        \n",
    "        # Check if we have the necessary coordinate columns\n",
    "        required_cols = ['x_1', 'y_1', 'z_1']\n",
    "        if not all(col in structure_data.columns for col in required_cols):\n",
    "            # Try to find alternative column names\n",
    "            alt_x_cols = [col for col in structure_data.columns if col.startswith('x_')]\n",
    "            if alt_x_cols:\n",
    "                x_col = alt_x_cols[0]\n",
    "                y_col = x_col.replace('x_', 'y_')\n",
    "                z_col = x_col.replace('x_', 'z_')\n",
    "                \n",
    "                # Rename columns for compatibility\n",
    "                if all(col in structure_data.columns for col in [x_col, y_col, z_col]):\n",
    "                    structure_data = structure_data.rename(columns={\n",
    "                        x_col: 'x_1',\n",
    "                        y_col: 'y_1',\n",
    "                        z_col: 'z_1'\n",
    "                    })\n",
    "                    print(f\"Renamed columns {x_col}, {y_col}, {z_col} to x_1, y_1, z_1\")\n",
    "                else:\n",
    "                    print(f\"Missing coordinate columns for {target_id}\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(f\"Missing coordinate columns for {target_id}\")\n",
    "                return None\n",
    "        \n",
    "        # Calculate dihedral features\n",
    "        output_file = DIHEDRAL_DIR / f\"{target_id}_dihedral_features.npz\"\n",
    "        print(f\"Calculating dihedral features for {len(structure_data)} residues\")\n",
    "        \n",
    "        dihedral_features = extract_dihedral_features(structure_data, output_file=output_file, include_raw_angles=True)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Extracted dihedral features in {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        # Add target ID\n",
    "        dihedral_features['target_id'] = target_id\n",
    "        return dihedral_features\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting dihedral features for {target_id}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def extract_mi_features_for_target(target_id, structure_data=None, msa_sequences=None):\n",
    "    \"\"\"\n",
    "    Extract Mutual Information features for a given target.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        structure_data: DataFrame with structure data for correlation calculation (optional)\n",
    "        msa_sequences: List of MSA sequences (optional, will be loaded if not provided)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with MI features or None if failed\n",
    "    \"\"\"\n",
    "    print(f\"Extracting MI features for {target_id}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Get MSA sequences if not provided\n",
    "        if msa_sequences is None:\n",
    "            msa_sequences = load_msa_data(target_id)\n",
    "            if msa_sequences is None or len(msa_sequences) < 2:\n",
    "                print(f\"Failed to get MSA data for {target_id} or not enough sequences\")\n",
    "                return None\n",
    "        \n",
    "        # Get structure data if not provided (for correlation calculation)\n",
    "        if structure_data is None and target_id is not None:\n",
    "            structure_data = load_structure_data(target_id)\n",
    "        \n",
    "        # Calculate MI (this may take some time for large MSAs)\n",
    "        print(f\"Calculating MI for {len(msa_sequences)} sequences\")\n",
    "        mi_result = calculate_mutual_information(msa_sequences, verbose=VERBOSE)\n",
    "        \n",
    "        if mi_result is None:\n",
    "            print(f\"Failed to calculate MI for {target_id}\")\n",
    "            return None\n",
    "        \n",
    "        # Convert to evolutionary features\n",
    "        output_file = MI_DIR / f\"{target_id}_mi_features.npz\"\n",
    "        \n",
    "        # If we have structure data, use it for correlation calculation\n",
    "        if structure_data is not None:\n",
    "            print(f\"Converting MI to evolutionary features with structural correlation\")\n",
    "            features = convert_mi_to_evolutionary_features(mi_result, structure_data, output_file=output_file)\n",
    "        else:\n",
    "            print(f\"Converting MI to evolutionary features without structural correlation\")\n",
    "            features = mi_result\n",
    "            \n",
    "            # Save manually if convert_mi_to_evolutionary_features wasn't used\n",
    "            if output_file is not None:\n",
    "                np.savez_compressed(output_file, **features)\n",
    "                print(f\"Saved MI features to {output_file}\")\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Extracted MI features in {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        # Add target ID\n",
    "        features['target_id'] = target_id\n",
    "        return features\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting MI features for {target_id}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing\n",
    "\n",
    "Process multiple targets in batch mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_target(target_id, extract_thermo=True, extract_dihedral=True, extract_mi=True):\n",
    "    \"\"\"\n",
    "    Process a single target, extracting all requested feature types.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        extract_thermo: Whether to extract thermodynamic features\n",
    "        extract_dihedral: Whether to extract dihedral features\n",
    "        extract_mi: Whether to extract MI features\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with results for each feature type\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing target: {target_id}\")\n",
    "    results = {'target_id': target_id}\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load common data that might be used by multiple feature types\n",
    "    sequence = get_sequence_for_target(target_id) if extract_thermo else None\n",
    "    structure_data = load_structure_data(target_id) if extract_dihedral or extract_mi else None\n",
    "    msa_sequences = load_msa_data(target_id) if extract_mi else None\n",
    "    \n",
    "    # Extract thermodynamic features\n",
    "    if extract_thermo:\n",
    "        thermo_file = THERMO_DIR / f\"{target_id}_thermo_features.npz\"\n",
    "        \n",
    "        if thermo_file.exists():\n",
    "            print(f\"Thermodynamic features already exist for {target_id}\")\n",
    "            results['thermo'] = {'success': True, 'skipped': True}\n",
    "        else:\n",
    "            thermo_features = extract_thermo_features_for_target(target_id, sequence)\n",
    "            results['thermo'] = {'success': thermo_features is not None}\n",
    "    \n",
    "    # Extract dihedral features\n",
    "    if extract_dihedral:\n",
    "        dihedral_file = DIHEDRAL_DIR / f\"{target_id}_dihedral_features.npz\"\n",
    "        \n",
    "        if dihedral_file.exists():\n",
    "            print(f\"Dihedral features already exist for {target_id}\")\n",
    "            results['dihedral'] = {'success': True, 'skipped': True}\n",
    "        else:\n",
    "            dihedral_features = extract_dihedral_features_for_target(target_id, structure_data)\n",
    "            results['dihedral'] = {'success': dihedral_features is not None}\n",
    "    \n",
    "    # Extract MI features\n",
    "    if extract_mi:\n",
    "        mi_file = MI_DIR / f\"{target_id}_mi_features.npz\"\n",
    "        \n",
    "        if mi_file.exists():\n",
    "            print(f\"MI features already exist for {target_id}\")\n",
    "            results['mi'] = {'success': True, 'skipped': True}\n",
    "        else:\n",
    "            mi_features = extract_mi_features_for_target(target_id, structure_data, msa_sequences)\n",
    "            results['mi'] = {'success': mi_features is not None}\n",
    "    \n",
    "    # Calculate total time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    results['elapsed_time'] = elapsed_time\n",
    "    print(f\"Completed processing {target_id} in {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def batch_process_targets(target_ids, extract_thermo=True, extract_dihedral=True, extract_mi=True):\n",
    "    \"\"\"\n",
    "    Process multiple targets in batch mode.\n",
    "    \n",
    "    Args:\n",
    "        target_ids: List of target IDs\n",
    "        extract_thermo: Whether to extract thermodynamic features\n",
    "        extract_dihedral: Whether to extract dihedral features\n",
    "        extract_mi: Whether to extract MI features\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with results for each target\n",
    "    \"\"\"\n",
    "    print(f\"Starting batch processing for {len(target_ids)} targets\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    results = {}\n",
    "    for i, target_id in enumerate(target_ids):\n",
    "        print(f\"\\nProcessing target {i+1}/{len(target_ids)}: {target_id}\")\n",
    "        \n",
    "        # Process the target\n",
    "        target_results = process_target(\n",
    "            target_id, \n",
    "            extract_thermo=extract_thermo, \n",
    "            extract_dihedral=extract_dihedral, \n",
    "            extract_mi=extract_mi\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        results[target_id] = target_results\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    success_counts = {\n",
    "        'thermo': sum(1 for r in results.values() if 'thermo' in r and r['thermo']['success']),\n",
    "        'dihedral': sum(1 for r in results.values() if 'dihedral' in r and r['dihedral']['success']),\n",
    "        'mi': sum(1 for r in results.values() if 'mi' in r and r['mi']['success'])\n",
    "    }\n",
    "    \n",
    "    skipped_counts = {\n",
    "        'thermo': sum(1 for r in results.values() if 'thermo' in r and r['thermo'].get('skipped', False)),\n",
    "        'dihedral': sum(1 for r in results.values() if 'dihedral' in r and r['dihedral'].get('skipped', False)),\n",
    "        'mi': sum(1 for r in results.values() if 'mi' in r and r['mi'].get('skipped', False))\n",
    "    }\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nBatch processing complete!\")\n",
    "    print(f\"Total targets: {len(target_ids)}\")\n",
    "    print(f\"Total time: {total_time:.2f} seconds\")\n",
    "    \n",
    "    if extract_thermo:\n",
    "        print(f\"Thermodynamic features: {success_counts['thermo']} successful ({skipped_counts['thermo']} skipped)\")\n",
    "        \n",
    "    if extract_dihedral:\n",
    "        print(f\"Dihedral features: {success_counts['dihedral']} successful ({skipped_counts['dihedral']} skipped)\")\n",
    "        \n",
    "    if extract_mi:\n",
    "        print(f\"MI features: {success_counts['mi']} successful ({skipped_counts['mi']} skipped)\")\n",
    "    \n",
    "    # Save summary\n",
    "    summary = {\n",
    "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'total_targets': len(target_ids),\n",
    "        'total_time': total_time,\n",
    "        'success_counts': success_counts,\n",
    "        'skipped_counts': skipped_counts,\n",
    "        'target_results': results\n",
    "    }\n",
    "    \n",
    "    with open(PROCESSED_DIR / 'validation_processing_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Process"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Load validation data file from different possible locations\nvalidation_paths = [\n    RAW_DIR / \"validation_labels.csv\",\n    RAW_DIR / \"validation\" / \"validation_labels.csv\"\n]\n\nvalidation_data = None\nfor validation_file in validation_paths:\n    if validation_file.exists():\n        validation_data = load_rna_data(validation_file)\n        if validation_data is not None:\n            break\n\nif validation_data is None:\n    print(\"Error loading validation data. Please make sure at least one validation file exists.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and Validation\n",
    "\n",
    "Visualize and validate the features."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Select a target for visualization\nif validation_data is not None and not validation_data.empty:\n    # Get unique target IDs\n    target_ids = get_unique_target_ids(validation_data)\n    \n    # Limit for testing\n    if LIMIT is not None and LIMIT < len(target_ids):\n        print(f\"Limiting to first {LIMIT} targets for testing\")\n        target_ids = target_ids[:LIMIT]\n    \n    # Process targets\n    results = batch_process_targets(\n        target_ids,\n        extract_thermo=True,\n        extract_dihedral=True,\n        extract_mi=True\n    )\nelse:\n    print(\"No validation data available. Please check your validation data files.\")\n    target_ids = []"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}