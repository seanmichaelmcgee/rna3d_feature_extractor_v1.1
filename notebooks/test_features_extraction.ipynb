{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA Test Features Extraction\n",
    "\n",
    "This notebook extracts features for RNA test data that does NOT include 3D structural information.\n",
    "Only the following features can be extracted for test data:\n",
    "1. Thermodynamic features from RNA sequences\n",
    "2. Mutual Information features from Multiple Sequence Alignments (MSAs)\n",
    "\n",
    "Note: Pseudodihedral angle features cannot be generated for test data since this requires 3D coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Ensure the parent directory is in the path so we can import our modules\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import feature extraction modules\n",
    "from src.analysis.thermodynamic_analysis import extract_thermodynamic_features\n",
    "from src.analysis.mutual_information import calculate_mutual_information, convert_mi_to_evolutionary_features\n",
    "from src.data.extract_features_simple import save_features_npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Define paths and parameters for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relative paths\n",
    "DATA_DIR = Path(\"../data\")\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "# Output directories for each feature type\n",
    "THERMO_DIR = PROCESSED_DIR / \"thermo_features\"\n",
    "MI_DIR = PROCESSED_DIR / \"mi_features\"\n",
    "\n",
    "# Make sure all directories exist\n",
    "for directory in [RAW_DIR, PROCESSED_DIR, THERMO_DIR, MI_DIR]:\n",
    "    directory.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Parameters\n",
    "LIMIT = 5  # Limit for testing; set to None to process all data\n",
    "VERBOSE = True  # Whether to print detailed progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Define utility functions for loading data and extracting features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rna_data(csv_path):\n",
    "    \"\"\"\n",
    "    Load RNA data from CSV file.\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to CSV file containing RNA data\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with RNA data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"Loaded {len(df)} entries from {csv_path}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_unique_target_ids(df, id_col=\"ID\"):\n",
    "    \"\"\"\n",
    "    Extract unique target IDs from dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with RNA data\n",
    "        id_col: Column containing IDs\n",
    "        \n",
    "    Returns:\n",
    "        List of unique target IDs\n",
    "    \"\"\"\n",
    "    # Extract target IDs (format: TARGET_ID_RESIDUE_NUM)\n",
    "    target_ids = []\n",
    "    for id_str in df[id_col]:\n",
    "        # Split the ID string and get the target ID part\n",
    "        parts = id_str.split('_')\n",
    "        if len(parts) >= 2:\n",
    "            target_id = f\"{parts[0]}_{parts[1]}\"  # Take the first two parts (e.g., \"1SCL_A\")\n",
    "            target_ids.append(target_id)\n",
    "    \n",
    "    # Get unique target IDs\n",
    "    unique_targets = sorted(list(set(target_ids)))\n",
    "    print(f\"Found {len(unique_targets)} unique target IDs\")\n",
    "    return unique_targets\n",
    "\n",
    "def load_msa_data(target_id, data_dir=RAW_DIR):\n",
    "    \"\"\"\n",
    "    Load MSA data for a given target.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        data_dir: Directory containing MSA data\n",
    "        \n",
    "    Returns:\n",
    "        List of MSA sequences or None if not found\n",
    "    \"\"\"\n",
    "    # Try to find the MSA file\n",
    "    msa_paths = [\n",
    "        data_dir / \"test\" / \"MSA\" / f\"{target_id}.MSA.fasta\",\n",
    "        data_dir / \"test\" / f\"{target_id}.MSA.fasta\",\n",
    "        data_dir / \"test\" / \"alignments\" / f\"{target_id}.MSA.fasta\"\n",
    "    ]\n",
    "    \n",
    "    for path in msa_paths:\n",
    "        if path.exists():\n",
    "            print(f\"Loading MSA data from {path}\")\n",
    "            try:\n",
    "                # Parse FASTA file\n",
    "                sequences = []\n",
    "                current_seq = \"\"\n",
    "                \n",
    "                with open(path, 'r') as f:\n",
    "                    for line in f:\n",
    "                        line = line.strip()\n",
    "                        if line.startswith('>'):\n",
    "                            if current_seq:\n",
    "                                sequences.append(current_seq)\n",
    "                                current_seq = \"\"\n",
    "                        else:\n",
    "                            current_seq += line\n",
    "                            \n",
    "                    # Add the last sequence\n",
    "                    if current_seq:\n",
    "                        sequences.append(current_seq)\n",
    "                \n",
    "                print(f\"Loaded {len(sequences)} sequences from MSA\")\n",
    "                return sequences\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading MSA data: {e}\")\n",
    "                return None\n",
    "    \n",
    "    print(f\"Could not find MSA data for {target_id}\")\n",
    "    return None\n",
    "\n",
    "def get_sequence_for_target(target_id, data_dir=RAW_DIR):\n",
    "    \"\"\"\n",
    "    Get RNA sequence for a target ID from the sequence file.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        data_dir: Directory containing sequence data\n",
    "        \n",
    "    Returns:\n",
    "        RNA sequence as string or None if not found\n",
    "    \"\"\"\n",
    "    # Try different possible file locations\n",
    "    sequence_paths = [\n",
    "        data_dir / \"test\" / \"sequences.csv\",\n",
    "        data_dir / \"test\" / \"test_sequences.csv\",\n",
    "        data_dir / \"test\" / \"rna_sequences.csv\"\n",
    "    ]\n",
    "    \n",
    "    for path in sequence_paths:\n",
    "        if path.exists():\n",
    "            try:\n",
    "                df = pd.read_csv(path)\n",
    "                \n",
    "                # Try different possible column names\n",
    "                id_cols = [\"target_id\", \"ID\", \"id\"]\n",
    "                seq_cols = [\"sequence\", \"Sequence\", \"seq\"]\n",
    "                \n",
    "                for id_col in id_cols:\n",
    "                    if id_col in df.columns:\n",
    "                        for seq_col in seq_cols:\n",
    "                            if seq_col in df.columns:\n",
    "                                # Find the target in the dataframe\n",
    "                                target_row = df[df[id_col] == target_id]\n",
    "                                if len(target_row) > 0:\n",
    "                                    sequence = target_row[seq_col].iloc[0]\n",
    "                                    return sequence\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading sequence data from {path}: {e}\")\n",
    "    \n",
    "    # If we still haven't found the sequence, try to extract it from MSA data\n",
    "    msa_sequences = load_msa_data(target_id, data_dir)\n",
    "    if msa_sequences and len(msa_sequences) > 0:\n",
    "        # The first sequence in the MSA is typically the target sequence\n",
    "        return msa_sequences[0]\n",
    "    \n",
    "    print(f\"Could not find sequence for {target_id}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Functions\n",
    "\n",
    "Define functions for extracting each type of feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_thermo_features_for_target(target_id, sequence=None):\n",
    "    \"\"\"\n",
    "    Extract thermodynamic features for a given target.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        sequence: RNA sequence (optional, will be loaded if not provided)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with thermodynamic features or None if failed\n",
    "    \"\"\"\n",
    "    print(f\"Extracting thermodynamic features for {target_id}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Get sequence if not provided\n",
    "        if sequence is None:\n",
    "            sequence = get_sequence_for_target(target_id)\n",
    "            if sequence is None:\n",
    "                print(f\"Failed to get sequence for {target_id}\")\n",
    "                return None\n",
    "        \n",
    "        # Calculate features\n",
    "        print(f\"Calculating thermodynamic features for sequence of length {len(sequence)}\")\n",
    "        features = extract_thermodynamic_features(sequence)\n",
    "        \n",
    "        # Save features\n",
    "        output_file = THERMO_DIR / f\"{target_id}_thermo_features.npz\"\n",
    "        features['target_id'] = target_id\n",
    "        features['sequence'] = sequence\n",
    "        \n",
    "        save_features_npz(features, output_file)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Extracted thermodynamic features in {elapsed_time:.2f} seconds\")\n",
    "        return features\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting thermodynamic features for {target_id}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def extract_mi_features_for_target(target_id, msa_sequences=None):\n",
    "    \"\"\"\n",
    "    Extract Mutual Information features for a given target.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        msa_sequences: List of MSA sequences (optional, will be loaded if not provided)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with MI features or None if failed\n",
    "    \"\"\"\n",
    "    print(f\"Extracting MI features for {target_id}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Get MSA sequences if not provided\n",
    "        if msa_sequences is None:\n",
    "            msa_sequences = load_msa_data(target_id)\n",
    "            if msa_sequences is None or len(msa_sequences) < 2:\n",
    "                print(f\"Failed to get MSA data for {target_id} or not enough sequences\")\n",
    "                return None\n",
    "        \n",
    "        # Calculate MI (this may take some time for large MSAs)\n",
    "        print(f\"Calculating MI for {len(msa_sequences)} sequences\")\n",
    "        mi_result = calculate_mutual_information(msa_sequences, verbose=VERBOSE)\n",
    "        \n",
    "        if mi_result is None:\n",
    "            print(f\"Failed to calculate MI for {target_id}\")\n",
    "            return None\n",
    "        \n",
    "        # Convert to evolutionary features\n",
    "        output_file = MI_DIR / f\"{target_id}_mi_features.npz\"\n",
    "        features = mi_result\n",
    "        \n",
    "        # Save features\n",
    "        np.savez_compressed(output_file, **features)\n",
    "        print(f\"Saved MI features to {output_file}\")\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Extracted MI features in {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        # Add target ID\n",
    "        features['target_id'] = target_id\n",
    "        return features\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting MI features for {target_id}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing\n",
    "\n",
    "Process multiple targets in batch mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_target(target_id, extract_thermo=True, extract_mi=True):\n",
    "    \"\"\"\n",
    "    Process a single target, extracting all requested feature types.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        extract_thermo: Whether to extract thermodynamic features\n",
    "        extract_mi: Whether to extract MI features\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with results for each feature type\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing target: {target_id}\")\n",
    "    results = {'target_id': target_id}\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load common data that might be used by multiple feature types\n",
    "    sequence = get_sequence_for_target(target_id) if extract_thermo else None\n",
    "    msa_sequences = load_msa_data(target_id) if extract_mi else None\n",
    "    \n",
    "    # Extract thermodynamic features\n",
    "    if extract_thermo:\n",
    "        thermo_file = THERMO_DIR / f\"{target_id}_thermo_features.npz\"\n",
    "        \n",
    "        if thermo_file.exists():\n",
    "            print(f\"Thermodynamic features already exist for {target_id}\")\n",
    "            results['thermo'] = {'success': True, 'skipped': True}\n",
    "        else:\n",
    "            thermo_features = extract_thermo_features_for_target(target_id, sequence)\n",
    "            results['thermo'] = {'success': thermo_features is not None}\n",
    "    \n",
    "    # Extract MI features\n",
    "    if extract_mi:\n",
    "        mi_file = MI_DIR / f\"{target_id}_mi_features.npz\"\n",
    "        \n",
    "        if mi_file.exists():\n",
    "            print(f\"MI features already exist for {target_id}\")\n",
    "            results['mi'] = {'success': True, 'skipped': True}\n",
    "        else:\n",
    "            mi_features = extract_mi_features_for_target(target_id, msa_sequences)\n",
    "            results['mi'] = {'success': mi_features is not None}\n",
    "    \n",
    "    # Calculate total time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    results['elapsed_time'] = elapsed_time\n",
    "    print(f\"Completed processing {target_id} in {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def batch_process_targets(target_ids, extract_thermo=True, extract_mi=True):\n",
    "    \"\"\"\n",
    "    Process multiple targets in batch mode.\n",
    "    \n",
    "    Args:\n",
    "        target_ids: List of target IDs\n",
    "        extract_thermo: Whether to extract thermodynamic features\n",
    "        extract_mi: Whether to extract MI features\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with results for each target\n",
    "    \"\"\"\n",
    "    print(f\"Starting batch processing for {len(target_ids)} targets\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    results = {}\n",
    "    for i, target_id in enumerate(target_ids):\n",
    "        print(f\"\\nProcessing target {i+1}/{len(target_ids)}: {target_id}\")\n",
    "        \n",
    "        # Process the target\n",
    "        target_results = process_target(\n",
    "            target_id, \n",
    "            extract_thermo=extract_thermo, \n",
    "            extract_mi=extract_mi\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        results[target_id] = target_results\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    success_counts = {\n",
    "        'thermo': sum(1 for r in results.values() if 'thermo' in r and r['thermo']['success']),\n",
    "        'mi': sum(1 for r in results.values() if 'mi' in r and r['mi']['success'])\n",
    "    }\n",
    "    \n",
    "    skipped_counts = {\n",
    "        'thermo': sum(1 for r in results.values() if 'thermo' in r and r['thermo'].get('skipped', False)),\n",
    "        'mi': sum(1 for r in results.values() if 'mi' in r and r['mi'].get('skipped', False))\n",
    "    }\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nBatch processing complete!\")\n",
    "    print(f\"Total targets: {len(target_ids)}\")\n",
    "    print(f\"Total time: {total_time:.2f} seconds\")\n",
    "    \n",
    "    if extract_thermo:\n",
    "        print(f\"Thermodynamic features: {success_counts['thermo']} successful ({skipped_counts['thermo']} skipped)\")\n",
    "        \n",
    "    if extract_mi:\n",
    "        print(f\"MI features: {success_counts['mi']} successful ({skipped_counts['mi']} skipped)\")\n",
    "    \n",
    "    # Save summary\n",
    "    summary = {\n",
    "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'total_targets': len(target_ids),\n",
    "        'total_time': total_time,\n",
    "        'success_counts': success_counts,\n",
    "        'skipped_counts': skipped_counts,\n",
    "        'target_results': results\n",
    "    }\n",
    "    \n",
    "    with open(PROCESSED_DIR / 'test_processing_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data from sequences.csv since there's no labels file for test data\n",
    "test_file = RAW_DIR / \"test\" / \"test_sequences.csv\"\n",
    "test_data = load_rna_data(test_file)\n",
    "\n",
    "if test_data is None:\n",
    "    # Try alternative file names\n",
    "    test_file = RAW_DIR / \"test\" / \"sequences.csv\"\n",
    "    test_data = load_rna_data(test_file)\n",
    "    \n",
    "    if test_data is None:\n",
    "        print(\"Error loading test data. Please make sure the file exists.\")\n",
    "        test_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Unique Target IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique target IDs\n",
    "if not test_data.empty:\n",
    "    # Look for ID column\n",
    "    id_col = None\n",
    "    for col_name in [\"target_id\", \"ID\", \"id\"]:\n",
    "        if col_name in test_data.columns:\n",
    "            id_col = col_name\n",
    "            break\n",
    "    \n",
    "    if id_col is None:\n",
    "        print(\"Error: Could not find ID column in test data\")\n",
    "        target_ids = []\n",
    "    else:\n",
    "        # For test data, the IDs might already be unique without residue numbers\n",
    "        # Check if IDs contain underscore\n",
    "        if any(\"_\" in str(id_val) for id_val in test_data[id_col]):\n",
    "            target_ids = get_unique_target_ids(test_data, id_col=id_col)\n",
    "        else:\n",
    "            # IDs are already unique targets\n",
    "            target_ids = test_data[id_col].unique().tolist()\n",
    "            print(f\"Found {len(target_ids)} unique target IDs\")\n",
    "    \n",
    "    # Limit for testing\n",
    "    if LIMIT is not None and LIMIT < len(target_ids):\n",
    "        print(f\"Limiting to first {LIMIT} targets for testing\")\n",
    "        target_ids = target_ids[:LIMIT]\n",
    "else:\n",
    "    target_ids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_ids:\n",
    "    # Process targets\n",
    "    results = batch_process_targets(\n",
    "        target_ids,\n",
    "        extract_thermo=True,\n",
    "        extract_mi=True\n",
    "    )\n",
    "else:\n",
    "    print(\"No targets to process. Please check your test data file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and Validation\n",
    "\n",
    "Visualize and validate the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load features for a target\n",
    "def load_features(target_id):\n",
    "    \"\"\"\n",
    "    Load features for a target ID.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with features from all three types\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Load thermodynamic features\n",
    "    thermo_file = THERMO_DIR / f\"{target_id}_thermo_features.npz\"\n",
    "    if thermo_file.exists():\n",
    "        features['thermo'] = dict(np.load(thermo_file, allow_pickle=True))\n",
    "    \n",
    "    # Load MI features\n",
    "    mi_file = MI_DIR / f\"{target_id}_mi_features.npz\"\n",
    "    if mi_file.exists():\n",
    "        features['mi'] = dict(np.load(mi_file, allow_pickle=True))\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Select a target for visualization\n",
    "if target_ids and len(target_ids) > 0:\n",
    "    example_target = target_ids[0]\n",
    "    print(f\"Visualizing features for example target: {example_target}\")\n",
    "    \n",
    "    # Load features\n",
    "    features = load_features(example_target)\n",
    "    \n",
    "    # Print available feature types\n",
    "    print(f\"Available feature types: {list(features.keys())}\")\n",
    "    \n",
    "    # Visualize thermodynamic features if available\n",
    "    if 'thermo' in features:\n",
    "        thermo = features['thermo']\n",
    "        print(\"\\nThermodynamic features:\")\n",
    "        \n",
    "        # Print basic features\n",
    "        for key in ['mfe', 'ensemble_energy', 'prob_of_mfe', 'mean_entropy']:\n",
    "            if key in thermo:\n",
    "                print(f\"  {key}: {thermo[key]}\")\n",
    "        \n",
    "        # Plot structure diagram if available\n",
    "        if 'structure' in thermo and 'sequence' in thermo:\n",
    "            sequence = str(thermo['sequence'])\n",
    "            structure = str(thermo['structure'])\n",
    "            \n",
    "            # Create a simple visualization of the structure\n",
    "            fig, ax = plt.subplots(figsize=(15, 3))\n",
    "            \n",
    "            # Plot paired bases as arcs\n",
    "            stack = []\n",
    "            pairs = []\n",
    "            for i, char in enumerate(structure):\n",
    "                if char == '(':\n",
    "                    stack.append(i)\n",
    "                elif char == ')':\n",
    "                    if stack:\n",
    "                        j = stack.pop()\n",
    "                        pairs.append((j, i))\n",
    "            \n",
    "            # Draw baselines\n",
    "            ax.plot([0, len(structure)], [0, 0], 'k-', lw=1, alpha=0.5)\n",
    "            \n",
    "            # Draw nucleotides\n",
    "            for i, base in enumerate(sequence):\n",
    "                ax.text(i, -0.1, base, ha='center', va='top', fontsize=8)\n",
    "            \n",
    "            # Draw arcs\n",
    "            for i, j in pairs:\n",
    "                center = (i + j) / 2\n",
    "                width = abs(j - i)\n",
    "                height = width / 5  # Adjust for aesthetics\n",
    "                ax.add_patch(plt.Rectangle((center - width/2, 0), width, height, \n",
    "                             facecolor='none', edgecolor='blue', alpha=0.5, \n",
    "                             transform=ax.transData.skewed(0, 0, 1, 0)))\n",
    "            \n",
    "            ax.set_title(f\"RNA Structure for {example_target}\")\n",
    "            ax.set_xlim(-1, len(structure) + 1)\n",
    "            ax.set_ylim(-0.5, (len(structure)/10) + 1)\n",
    "            ax.set_yticks([])\n",
    "            ax.set_xticks(range(0, len(structure), 10))\n",
    "            plt.show()\n",
    "        \n",
    "        # Plot positional entropy if available\n",
    "        if 'position_entropy' in thermo:\n",
    "            entropy = thermo['position_entropy']\n",
    "            \n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.plot(range(len(entropy)), entropy, 'b-')\n",
    "            plt.title(f\"Positional Entropy for {example_target}\")\n",
    "            plt.xlabel(\"Position\")\n",
    "            plt.ylabel(\"Entropy\")\n",
    "            plt.grid(alpha=0.3)\n",
    "            plt.show()\n",
    "    \n",
    "    # Visualize MI features if available\n",
    "    if 'mi' in features:\n",
    "        mi = features['mi']\n",
    "        print(\"\\nMI features:\")\n",
    "        \n",
    "        # Print top pairs if available\n",
    "        if 'top_pairs' in mi and len(mi['top_pairs']) > 0:\n",
    "            top_pairs = mi['top_pairs']\n",
    "            print(f\"  Top 5 MI pairs:\")\n",
    "            for i in range(min(5, len(top_pairs))):\n",
    "                pair = top_pairs[i]\n",
    "                print(f\"    {pair[0]} - {pair[1]}: {pair[2]:.4f}\")\n",
    "        \n",
    "        # Plot MI matrix if available\n",
    "        if 'scores' in mi:\n",
    "            scores = mi['scores']\n",
    "            \n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.imshow(scores, cmap='viridis', origin='lower')\n",
    "            plt.colorbar(label='Mutual Information')\n",
    "            plt.title(f\"Mutual Information Matrix for {example_target}\")\n",
    "            plt.xlabel(\"Position\")\n",
    "            plt.ylabel(\"Position\")\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"No targets available for visualization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}