{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA Test Features Extraction\n",
    "\n",
    "This notebook extracts features for RNA test data that does NOT include 3D structural information.\n",
    "Only the following features can be extracted for test data:\n",
    "1. Thermodynamic features from RNA sequences\n",
    "2. Mutual Information features from Multiple Sequence Alignments (MSAs)\n",
    "\n",
    "Note: Pseudodihedral angle features cannot be generated for test data since this requires 3D coordinates.\n",
    "\n",
    "## Dependencies\n",
    "- ViennaRNA (for thermodynamic features)\n",
    "- NumPy/SciPy/Pandas (core data processing)\n",
    "- Memory monitoring tools from src.analysis.memory_monitor\n",
    "- Feature extraction functions from src.analysis modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViennaRNA module imported successfully (version: 2.6.4)\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import psutil\n",
    "\n",
    "# Ensure the parent directory is in the path so we can import our modules\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import feature extraction modules\n",
    "from src.analysis.thermodynamic_analysis import extract_thermodynamic_features\n",
    "from src.analysis.dihedral_analysis import extract_dihedral_features\n",
    "from src.analysis.mutual_information import calculate_mutual_information, convert_mi_to_evolutionary_features\n",
    "from src.data.extract_features_simple import save_features_npz\n",
    "\n",
    "# Import memory monitoring utilities\n",
    "from src.analysis.memory_monitor import MemoryTracker, log_memory_usage, plot_memory_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "# Define paths and parameters for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relative paths\n",
    "DATA_DIR = Path(\"../data\")\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "# Output directories for each feature type\n",
    "THERMO_DIR = PROCESSED_DIR / \"thermo_features\"\n",
    "DIHEDRAL_DIR = PROCESSED_DIR / \"dihedral_features\"\n",
    "MI_DIR = PROCESSED_DIR / \"mi_features\"\n",
    "MEMORY_PLOTS_DIR = PROCESSED_DIR / \"memory_plots\"\n",
    "\n",
    "# Make sure all directories exist\n",
    "for directory in [RAW_DIR, PROCESSED_DIR, THERMO_DIR, DIHEDRAL_DIR, MI_DIR, MEMORY_PLOTS_DIR]:\n",
    "            directory.mkdir(exist_ok=True, parents=True)\n",
    "            \n",
    "# Parameters\n",
    "LIMIT = 5  # Limit for testing; set to None to process all data\n",
    "VERBOSE = True  # Whether to print detailed progress\n",
    "\n",
    "# Auto-detect if running on Kaggle\n",
    "KAGGLE_MODE = os.environ.get('KAGGLE_KERNEL_RUN_TYPE') is not None\n",
    "if KAGGLE_MODE:\n",
    "        print(\"Running in Kaggle environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "\n",
    "# Define utility functions for loading data and extracting features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rna_data(csv_path):\n",
    "    \"\"\"\n",
    "    Load RNA data from CSV file.\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to CSV file containing RNA data\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with RNA data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"Loaded {len(df)} entries from {csv_path}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_unique_target_ids(df, id_col=\"ID\"):\n",
    "    \"\"\"\n",
    "    Extract unique target IDs from dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with RNA data\n",
    "        id_col: Column containing IDs\n",
    "        \n",
    "    Returns:\n",
    "        List of unique target IDs\n",
    "    \"\"\"\n",
    "    # Extract target IDs (format: TARGET_ID_RESIDUE_NUM)\n",
    "    target_ids = []\n",
    "    for id_str in df[id_col]:\n",
    "        # Split the ID string and get the target ID part\n",
    "        parts = id_str.split('_')\n",
    "        if len(parts) >= 2:\n",
    "            target_id = f\"{parts[0]}_{parts[1]}\"  # Take the first two parts (e.g., \"1SCL_A\")\n",
    "            target_ids.append(target_id)\n",
    "    \n",
    "    # Get unique target IDs\n",
    "    unique_targets = sorted(list(set(target_ids)))\n",
    "    print(f\"Found {len(unique_targets)} unique target IDs\")\n",
    "    return unique_targets\n",
    "\n",
    "def load_msa_data(target_id, data_dir=RAW_DIR):\n",
    "    \"\"\"\n",
    "    Load MSA data for a given target.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        data_dir: Directory containing MSA data\n",
    "        \n",
    "    Returns:\n",
    "        List of MSA sequences or None if not found\n",
    "    \"\"\"\n",
    "    # Define possible MSA directories and extensions\n",
    "    msa_dirs = [\n",
    "        data_dir / \"MSA\",\n",
    "        data_dir,\n",
    "        data_dir / \"alignments\",\n",
    "        data_dir / \"test\" / \"MSA\",\n",
    "        data_dir / \"test\",\n",
    "        data_dir / \"test\" / \"alignments\"\n",
    "    ]\n",
    "    \n",
    "    extensions = [\".MSA.fasta\", \".fasta\", \".fa\", \".afa\", \".msa\"]\n",
    "    \n",
    "    # Try all combinations of directories and extensions\n",
    "    for msa_dir in msa_dirs:\n",
    "        if not msa_dir.exists():\n",
    "            continue\n",
    "            \n",
    "        for ext in extensions:\n",
    "            msa_path = msa_dir / f\"{target_id}{ext}\"\n",
    "            if msa_path.exists():\n",
    "                print(f\"Loading MSA data from {msa_path}\")\n",
    "                try:\n",
    "                    # Parse FASTA file\n",
    "                    sequences = []\n",
    "                    current_seq = \"\"\n",
    "                    \n",
    "                    with open(msa_path, 'r') as f:\n",
    "                        for line in f:\n",
    "                            line = line.strip()\n",
    "                            if line.startswith('>'):\n",
    "                                if current_seq:\n",
    "                                    sequences.append(current_seq)\n",
    "                                    current_seq = \"\"\n",
    "                            else:\n",
    "                                current_seq += line\n",
    "                                \n",
    "                        # Add the last sequence\n",
    "                        if current_seq:\n",
    "                            sequences.append(current_seq)\n",
    "                    \n",
    "                    print(f\"Loaded {len(sequences)} sequences from MSA\")\n",
    "                    return sequences\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading MSA data: {e}\")\n",
    "    \n",
    "    # Fallback: try recursive search\n",
    "    print(f\"MSA file not found in standard locations, trying recursive search...\")\n",
    "    try:\n",
    "        for msa_dir in [data_dir, data_dir / \"test\"]:\n",
    "            if not msa_dir.exists():\n",
    "                continue\n",
    "                \n",
    "            for ext in extensions:\n",
    "                pattern = f\"**/{target_id}{ext}\"\n",
    "                matches = list(msa_dir.glob(pattern))\n",
    "                if matches:\n",
    "                    msa_path = matches[0]\n",
    "                    print(f\"Found MSA via recursive search: {msa_path}\")\n",
    "                    \n",
    "                    # Parse the file\n",
    "                    sequences = []\n",
    "                    current_seq = \"\"\n",
    "                    \n",
    "                    with open(msa_path, 'r') as f:\n",
    "                        for line in f:\n",
    "                            line = line.strip()\n",
    "                            if line.startswith('>'):\n",
    "                                if current_seq:\n",
    "                                    sequences.append(current_seq)\n",
    "                                    current_seq = \"\"\n",
    "                            else:\n",
    "                                current_seq += line\n",
    "                                \n",
    "                        # Add the last sequence\n",
    "                        if current_seq:\n",
    "                            sequences.append(current_seq)\n",
    "                    \n",
    "                    print(f\"Loaded {len(sequences)} sequences from MSA\")\n",
    "                    return sequences\n",
    "    except Exception as e:\n",
    "        print(f\"Error in recursive MSA search: {e}\")\n",
    "    \n",
    "    print(f\"Could not find MSA data for {target_id}\")\n",
    "    return None\n",
    "\n",
    "def get_sequence_for_target(target_id, data_dir=RAW_DIR):\n",
    "    \"\"\"\n",
    "    Get RNA sequence for a target ID from the sequence file.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        data_dir: Directory containing sequence data\n",
    "        \n",
    "    Returns:\n",
    "        RNA sequence as string or None if not found\n",
    "    \"\"\"\n",
    "    # Try different possible file locations\n",
    "    sequence_paths = [\n",
    "        data_dir / \"test\" / \"sequences.csv\",\n",
    "        data_dir / \"test\" / \"test_sequences.csv\",\n",
    "        data_dir / \"test\" / \"rna_sequences.csv\",\n",
    "        data_dir / \"test_sequences.csv\",\n",
    "        data_dir / \"sequences.csv\"\n",
    "    ]\n",
    "    \n",
    "    for path in sequence_paths:\n",
    "        if path.exists():\n",
    "            try:\n",
    "                df = pd.read_csv(path)\n",
    "                \n",
    "                # Try different possible column names\n",
    "                id_cols = [\"target_id\", \"ID\", \"id\"]\n",
    "                seq_cols = [\"sequence\", \"Sequence\", \"seq\"]\n",
    "                \n",
    "                for id_col in id_cols:\n",
    "                    if id_col in df.columns:\n",
    "                        for seq_col in seq_cols:\n",
    "                            if seq_col in df.columns:\n",
    "                                # Find the target in the dataframe\n",
    "                                target_row = df[df[id_col] == target_id]\n",
    "                                if len(target_row) > 0:\n",
    "                                    sequence = target_row[seq_col].iloc[0]\n",
    "                                    return sequence\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading sequence data from {path}: {e}\")\n",
    "    \n",
    "    # If we still haven't found the sequence, try to extract it from MSA data\n",
    "    msa_sequences = load_msa_data(target_id, data_dir)\n",
    "    if msa_sequences and len(msa_sequences) > 0:\n",
    "        # The first sequence in the MSA is typically the target sequence\n",
    "        return msa_sequences[0]\n",
    "    \n",
    "    print(f\"Could not find sequence for {target_id}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Functions\n",
    "\n",
    "Define functions for extracting each type of feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_thermo_features_for_target(target_id, sequence=None):\n",
    "    \"\"\"\n",
    "    Extract thermodynamic features for a given target.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        sequence: RNA sequence (optional, will be loaded if not provided)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with thermodynamic features or None if failed\n",
    "    \"\"\"\n",
    "    print(f\"Extracting thermodynamic features for {target_id}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Get sequence if not provided\n",
    "        if sequence is None:\n",
    "            sequence = get_sequence_for_target(target_id)\n",
    "            if sequence is None:\n",
    "                print(f\"Failed to get sequence for {target_id}\")\n",
    "                return None\n",
    "        \n",
    "        # Log initial memory usage\n",
    "        log_memory_usage(f\"Before thermo features for {target_id} (len={len(sequence)})\")\n",
    "        \n",
    "        # Calculate features with memory monitoring\n",
    "        print(f\"Calculating thermodynamic features for sequence of length {len(sequence)}\")\n",
    "        with MemoryTracker(f\"Thermodynamic features calculation for {target_id}\"):\n",
    "            features = extract_thermodynamic_features(sequence)\n",
    "        \n",
    "        # Save features\n",
    "        output_file = THERMO_DIR / f\"{target_id}_thermo_features.npz\"\n",
    "        features['target_id'] = target_id\n",
    "        features['sequence'] = sequence\n",
    "        \n",
    "        with MemoryTracker(\"Saving thermodynamic features\"):\n",
    "            save_features_npz(features, output_file)\n",
    "        \n",
    "        # Log final memory usage\n",
    "        log_memory_usage(f\"After thermo features for {target_id}\")\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Extracted thermodynamic features in {elapsed_time:.2f} seconds\")\n",
    "        return features\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting thermodynamic features for {target_id}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def extract_mi_features_for_target(target_id, msa_sequences=None):\n",
    "    \"\"\"\n",
    "    Extract Mutual Information features for a given target.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        msa_sequences: List of MSA sequences (optional, will be loaded if not provided)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with MI features or None if failed\n",
    "    \"\"\"\n",
    "    print(f\"Extracting MI features for {target_id}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Get MSA sequences if not provided\n",
    "        if msa_sequences is None:\n",
    "            msa_sequences = load_msa_data(target_id)\n",
    "            if msa_sequences is None or len(msa_sequences) < 2:\n",
    "                print(f\"Failed to get MSA data for {target_id} or not enough sequences\")\n",
    "                return None\n",
    "        \n",
    "        # Log memory before MI calculation\n",
    "        sequence_length = len(msa_sequences[0]) if msa_sequences else 0\n",
    "        msa_size = len(msa_sequences) if msa_sequences else 0\n",
    "        log_memory_usage(f\"Before MI features for {target_id} (seq_len={sequence_length}, msa_size={msa_size})\")\n",
    "        \n",
    "        # Calculate MI (this may take some time for large MSAs)\n",
    "        print(f\"Calculating MI for {len(msa_sequences)} sequences\")\n",
    "        with MemoryTracker(f\"MI calculation for {target_id}\"):\n",
    "            mi_result = calculate_mutual_information(msa_sequences, verbose=VERBOSE)\n",
    "        \n",
    "        if mi_result is None:\n",
    "            print(f\"Failed to calculate MI for {target_id}\")\n",
    "            return None\n",
    "        \n",
    "        # Convert to evolutionary features\n",
    "        output_file = MI_DIR / f\"{target_id}_mi_features.npz\"\n",
    "        features = mi_result\n",
    "        \n",
    "        # Save features\n",
    "        with MemoryTracker(f\"Saving MI features for {target_id}\"):\n",
    "            np.savez_compressed(output_file, **features)\n",
    "        print(f\"Saved MI features to {output_file}\")\n",
    "        \n",
    "        # Log memory after MI calculation\n",
    "        log_memory_usage(f\"After MI features for {target_id}\")\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Extracted MI features in {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        # Add target ID\n",
    "        features['target_id'] = target_id\n",
    "        return features\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting MI features for {target_id}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing\n",
    "\n",
    "Process multiple targets in batch mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_target(target_id, extract_thermo=True, extract_mi=True):\n",
    "    \"\"\"\n",
    "    Process a single target, extracting all requested feature types.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        extract_thermo: Whether to extract thermodynamic features\n",
    "        extract_mi: Whether to extract MI features\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with results for each feature type\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing target: {target_id}\")\n",
    "    results = {'target_id': target_id}\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load common data that might be used by multiple feature types\n",
    "    sequence = get_sequence_for_target(target_id) if extract_thermo else None\n",
    "    msa_sequences = load_msa_data(target_id) if extract_mi else None\n",
    "    \n",
    "    # Extract thermodynamic features\n",
    "    if extract_thermo:\n",
    "        thermo_file = THERMO_DIR / f\"{target_id}_thermo_features.npz\"\n",
    "        \n",
    "        if thermo_file.exists():\n",
    "            print(f\"Thermodynamic features already exist for {target_id}\")\n",
    "            results['thermo'] = {'success': True, 'skipped': True}\n",
    "        else:\n",
    "            thermo_features = extract_thermo_features_for_target(target_id, sequence)\n",
    "            results['thermo'] = {'success': thermo_features is not None}\n",
    "    \n",
    "    # Extract MI features\n",
    "    if extract_mi:\n",
    "        mi_file = MI_DIR / f\"{target_id}_mi_features.npz\"\n",
    "        \n",
    "        if mi_file.exists():\n",
    "            print(f\"MI features already exist for {target_id}\")\n",
    "            results['mi'] = {'success': True, 'skipped': True}\n",
    "        else:\n",
    "            mi_features = extract_mi_features_for_target(target_id, msa_sequences)\n",
    "            results['mi'] = {'success': mi_features is not None}\n",
    "    \n",
    "    # Calculate total time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    results['elapsed_time'] = elapsed_time\n",
    "    print(f\"Completed processing {target_id} in {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def batch_process_targets(target_ids, extract_thermo=True, extract_mi=True):\n",
    "    \"\"\"\n",
    "    Process multiple targets in batch mode.\n",
    "    \n",
    "    Args:\n",
    "        target_ids: List of target IDs\n",
    "        extract_thermo: Whether to extract thermodynamic features\n",
    "        extract_mi: Whether to extract MI features\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with results for each target\n",
    "    \"\"\"\n",
    "    print(f\"Starting batch processing for {len(target_ids)} targets\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    results = {}\n",
    "    for i, target_id in enumerate(target_ids):\n",
    "        print(f\"\\nProcessing target {i+1}/{len(target_ids)}: {target_id}\")\n",
    "        \n",
    "        # Process the target\n",
    "        target_results = process_target(\n",
    "            target_id, \n",
    "            extract_thermo=extract_thermo, \n",
    "            extract_mi=extract_mi\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        results[target_id] = target_results\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    success_counts = {\n",
    "        'thermo': sum(1 for r in results.values() if 'thermo' in r and r['thermo']['success']),\n",
    "        'mi': sum(1 for r in results.values() if 'mi' in r and r['mi']['success'])\n",
    "    }\n",
    "    \n",
    "    skipped_counts = {\n",
    "        'thermo': sum(1 for r in results.values() if 'thermo' in r and r['thermo'].get('skipped', False)),\n",
    "        'mi': sum(1 for r in results.values() if 'mi' in r and r['mi'].get('skipped', False))\n",
    "    }\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nBatch processing complete!\")\n",
    "    print(f\"Total targets: {len(target_ids)}\")\n",
    "    print(f\"Total time: {total_time:.2f} seconds\")\n",
    "    \n",
    "    if extract_thermo:\n",
    "        print(f\"Thermodynamic features: {success_counts['thermo']} successful ({skipped_counts['thermo']} skipped)\")\n",
    "        \n",
    "    if extract_mi:\n",
    "        print(f\"MI features: {success_counts['mi']} successful ({skipped_counts['mi']} skipped)\")\n",
    "    \n",
    "    # Save summary\n",
    "    summary = {\n",
    "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'total_targets': len(target_ids),\n",
    "        'total_time': total_time,\n",
    "        'success_counts': success_counts,\n",
    "        'skipped_counts': skipped_counts,\n",
    "        'target_results': results\n",
    "    }\n",
    "    \n",
    "    with open(PROCESSED_DIR / 'test_processing_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 entries from ../data/raw/test_sequences.csv\n"
     ]
    }
   ],
   "source": [
    "# Load test data file or try to find test labels file\n",
    "test_paths = [\n",
    "    RAW_DIR / \"test_sequences.csv\",\n",
    "    RAW_DIR / \"test\" / \"sequences.csv\"\n",
    "]\n",
    "\n",
    "test_data = None\n",
    "for test_file in test_paths:\n",
    "    if test_file.exists():\n",
    "        test_data = load_rna_data(test_file)\n",
    "        if test_data is not None:\n",
    "            break\n",
    "\n",
    "if test_data is None:\n",
    "    print(\"Error loading test data. Please make sure at least one test file exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Unique Target IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 unique target IDs\n",
      "Limiting to first 5 targets for testing\n"
     ]
    }
   ],
   "source": [
    "# Get unique target IDs\n",
    "if test_data is not None and not test_data.empty:\n",
    "    # Look for ID column\n",
    "    id_col = None\n",
    "    for col_name in [\"target_id\", \"ID\", \"id\"]:\n",
    "        if col_name in test_data.columns:\n",
    "            id_col = col_name\n",
    "            break\n",
    "    \n",
    "    if id_col is None:\n",
    "        print(\"Error: Could not find ID column in test data\")\n",
    "        target_ids = []\n",
    "    else:\n",
    "        # For test data, the IDs might already be unique without residue numbers\n",
    "        # Check if IDs contain underscore\n",
    "        if any(\"_\" in str(id_val) for id_val in test_data[id_col]):\n",
    "            target_ids = get_unique_target_ids(test_data, id_col=id_col)\n",
    "        else:\n",
    "            # IDs are already unique targets\n",
    "            target_ids = test_data[id_col].unique().tolist()\n",
    "            print(f\"Found {len(target_ids)} unique target IDs\")\n",
    "    \n",
    "    # Limit for testing\n",
    "    if LIMIT is not None and LIMIT < len(target_ids):\n",
    "        print(f\"Limiting to first {LIMIT} targets for testing\")\n",
    "        target_ids = target_ids[:LIMIT]\n",
    "else:\n",
    "    print(\"No test data available. Please check your test data files.\")\n",
    "    target_ids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch processing for 5 targets\n",
      "\n",
      "Processing target 1/5: R1107\n",
      "\n",
      "Processing target: R1107\n",
      "Loading MSA data from ../data/raw/MSA/R1107.MSA.fasta\n",
      "Loaded 1810 sequences from MSA\n",
      "Thermodynamic features already exist for R1107\n",
      "MI features already exist for R1107\n",
      "Completed processing R1107 in 0.00 seconds\n",
      "\n",
      "Processing target 2/5: R1108\n",
      "\n",
      "Processing target: R1108\n",
      "Loading MSA data from ../data/raw/MSA/R1108.MSA.fasta\n",
      "Loaded 3183 sequences from MSA\n",
      "Thermodynamic features already exist for R1108\n",
      "MI features already exist for R1108\n",
      "Completed processing R1108 in 0.00 seconds\n",
      "\n",
      "Processing target 3/5: R1116\n",
      "\n",
      "Processing target: R1116\n",
      "Loading MSA data from ../data/raw/MSA/R1116.MSA.fasta\n",
      "Loaded 2021 sequences from MSA\n",
      "Thermodynamic features already exist for R1116\n",
      "MI features already exist for R1116\n",
      "Completed processing R1116 in 0.00 seconds\n",
      "\n",
      "Processing target 4/5: R1117v2\n",
      "\n",
      "Processing target: R1117v2\n",
      "Loading MSA data from ../data/raw/MSA/R1117v2.MSA.fasta\n",
      "Loaded 192 sequences from MSA\n",
      "Thermodynamic features already exist for R1117v2\n",
      "MI features already exist for R1117v2\n",
      "Completed processing R1117v2 in 0.00 seconds\n",
      "\n",
      "Processing target 5/5: R1126\n",
      "\n",
      "Processing target: R1126\n",
      "Loading MSA data from ../data/raw/MSA/R1126.MSA.fasta\n",
      "Loaded 2 sequences from MSA\n",
      "Thermodynamic features already exist for R1126\n",
      "MI features already exist for R1126\n",
      "Completed processing R1126 in 0.00 seconds\n",
      "\n",
      "Batch processing complete!\n",
      "Total targets: 5\n",
      "Total time: 0.01 seconds\n",
      "Thermodynamic features: 5 successful (5 skipped)\n",
      "MI features: 5 successful (5 skipped)\n",
      "\n",
      "Verifying processed features for compatibility...\n",
      "\n",
      "================================================================================\n",
      "Verifying RNA Feature Compatibility in: ../data/processed\n",
      "================================================================================\n",
      "\n",
      "Checking directory structure in ../data/processed...\n",
      "✅ Found required directory: dihedral_features\n",
      "✅ Found required directory: thermo_features\n",
      "✅ Found required directory: mi_features\n",
      "\n",
      "Found 20 targets with features\n",
      "Target IDs: 17RA_A, 17RA_A_mi, 1A1T_B, 1A1T_B_mi, 1A4T_A...\n",
      "\n",
      "Verifying features for target ID: 17RA_A\n",
      "Found 2/3 feature types:\n",
      "✅ Dihedral features: Dihedral features valid with shape (21, 4)\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (21, 21)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 17RA_A_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (21, 21)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A1T_B\n",
      "Found 2/3 feature types:\n",
      "✅ Dihedral features: Dihedral features valid with shape (20, 4)\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (20, 20)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A1T_B_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (20, 20)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A4T_A\n",
      "Found 2/3 feature types:\n",
      "✅ Dihedral features: Dihedral features valid with shape (15, 4)\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (15, 15)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A4T_A_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (15, 15)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A51_A\n",
      "Found 2/3 feature types:\n",
      "✅ Dihedral features: Dihedral features valid with shape (41, 4)\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (41, 41)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A51_A_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (41, 41)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A60_A\n",
      "Found 2/3 feature types:\n",
      "✅ Dihedral features: Dihedral features valid with shape (44, 4)\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (44, 44)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: 1A60_A_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (44, 44)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1107\n",
      "Found 3/3 feature types:\n",
      "✅ Dihedral features: Dihedral features valid with shape (69, 4)\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (69, 69)\n",
      "✅ Mi features: MI features valid with matrix shape (69, 69)\n",
      "✅ Data loader simulation successful\n",
      "  Loaded feature groups:\n",
      "  - dihedral: features\n",
      "  - thermo: pairing_probs, positional_entropy\n",
      "  - evolutionary: coupling_matrix\n",
      "\n",
      "Verifying features for target ID: R1107_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (69, 69)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1108\n",
      "Found 1/3 feature types:\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (69, 69)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1108_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (69, 69)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1116\n",
      "Found 1/3 feature types:\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (157, 157)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1116_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (157, 157)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1117v2\n",
      "Found 1/3 feature types:\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (30, 30)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1117v2_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (30, 30)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1126\n",
      "Found 1/3 feature types:\n",
      "✅ Thermo features: Thermodynamic features valid with matrix shape (363, 363)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "Verifying features for target ID: R1126_mi\n",
      "Found 1/3 feature types:\n",
      "✅ Mi features: MI features valid with matrix shape (363, 363)\n",
      "✅ Data loader simulation successful\n",
      "\n",
      "================================================================================\n",
      "Feature Verification Summary:\n",
      "- Total targets: 20\n",
      "- Valid targets: 20\n",
      "- Invalid targets: 0\n",
      "\n",
      "✅ All features are compatible with the data loader\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if target_ids:\n",
    "    # Process targets\n",
    "    results = batch_process_targets(\n",
    "        target_ids,\n",
    "        extract_thermo=True,\n",
    "        extract_mi=True\n",
    "    )\n",
    "    \n",
    "    # Verify features\n",
    "    print(\"\\nVerifying processed features for compatibility...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    verification_script = Path(\"../scripts/verify_feature_compatibility.py\")\n",
    "    if verification_script.exists():\n",
    "        try:\n",
    "            # Run the script as a subprocess\n",
    "            cmd = [sys.executable, str(verification_script), str(PROCESSED_DIR), \"--verbose\"]\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "            \n",
    "            # Print the output\n",
    "            print(result.stdout)\n",
    "            \n",
    "            # Check for errors\n",
    "            if result.returncode != 0:\n",
    "                print(f\"Verification failed with exit code {result.returncode}\")\n",
    "                if result.stderr:\n",
    "                    print(f\"Error output: {result.stderr}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error running verification script: {e}\")\n",
    "    else:\n",
    "        print(f\"Warning: Feature verification script not found at {verification_script}\")\n",
    "        \n",
    "else:\n",
    "    print(\"No targets to process. Please check your test data file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and Validation\n",
    "\n",
    "Visualize and validate the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing features for example target: R1107\n",
      "Available feature types: ['thermo', 'mi']\n",
      "\n",
      "Thermodynamic features:\n",
      "  mfe: -21.600000381469727\n",
      "  ensemble_energy: -21.590000381469725\n",
      "  prob_of_mfe: 0.03317093058302927\n",
      "  mean_entropy: 1.906566868590242\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CompositeGenericTransform' object has no attribute 'skewed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 80\u001b[0m\n\u001b[1;32m     76\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(j \u001b[38;5;241m-\u001b[39m i)\n\u001b[1;32m     77\u001b[0m     height \u001b[38;5;241m=\u001b[39m width \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# Adjust for aesthetics\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     ax\u001b[38;5;241m.\u001b[39madd_patch(plt\u001b[38;5;241m.\u001b[39mRectangle((center \u001b[38;5;241m-\u001b[39m width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m), width, height, \n\u001b[1;32m     79\u001b[0m                  facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, \n\u001b[0;32m---> 80\u001b[0m                  transform\u001b[38;5;241m=\u001b[39m\u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskewed\u001b[49m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)))\n\u001b[1;32m     82\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRNA Structure for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_target\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_xlim(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(structure) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CompositeGenericTransform' object has no attribute 'skewed'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to load features for a target\n",
    "def load_features(target_id):\n",
    "    \"\"\"\n",
    "    Load features for a target ID.\n",
    "    \n",
    "    Args:\n",
    "        target_id: Target ID\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with features from all three types\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Load thermodynamic features\n",
    "    thermo_file = THERMO_DIR / f\"{target_id}_thermo_features.npz\"\n",
    "    if thermo_file.exists():\n",
    "        features['thermo'] = dict(np.load(thermo_file, allow_pickle=True))\n",
    "    \n",
    "    # Load MI features\n",
    "    mi_file = MI_DIR / f\"{target_id}_mi_features.npz\"\n",
    "    if mi_file.exists():\n",
    "        features['mi'] = dict(np.load(mi_file, allow_pickle=True))\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Select a target for visualization\n",
    "if target_ids and len(target_ids) > 0:\n",
    "    example_target = target_ids[0]\n",
    "    print(f\"Visualizing features for example target: {example_target}\")\n",
    "    \n",
    "    # Load features\n",
    "    features = load_features(example_target)\n",
    "    \n",
    "    # Print available feature types\n",
    "    print(f\"Available feature types: {list(features.keys())}\")\n",
    "    \n",
    "    # Visualize thermodynamic features if available\n",
    "    if 'thermo' in features:\n",
    "        thermo = features['thermo']\n",
    "        print(\"\\nThermodynamic features:\")\n",
    "        \n",
    "        # Print basic features\n",
    "        for key in ['mfe', 'ensemble_energy', 'prob_of_mfe', 'mean_entropy']:\n",
    "            if key in thermo:\n",
    "                print(f\"  {key}: {thermo[key]}\")\n",
    "        \n",
    "        # Plot structure diagram if available\n",
    "        if 'structure' in thermo and 'sequence' in thermo:\n",
    "            sequence = str(thermo['sequence'])\n",
    "            structure = str(thermo['structure'])\n",
    "            \n",
    "            # Create a simple visualization of the structure\n",
    "            fig, ax = plt.subplots(figsize=(15, 3))\n",
    "            \n",
    "            # Plot paired bases as arcs\n",
    "            stack = []\n",
    "            pairs = []\n",
    "            for i, char in enumerate(structure):\n",
    "                if char == '(':\n",
    "                    stack.append(i)\n",
    "                elif char == ')':\n",
    "                    if stack:\n",
    "                        j = stack.pop()\n",
    "                        pairs.append((j, i))\n",
    "            \n",
    "            # Draw baselines\n",
    "            ax.plot([0, len(structure)], [0, 0], 'k-', lw=1, alpha=0.5)\n",
    "            \n",
    "            # Draw nucleotides\n",
    "            for i, base in enumerate(sequence):\n",
    "                ax.text(i, -0.1, base, ha='center', va='top', fontsize=8)\n",
    "            \n",
    "            # Draw arcs\n",
    "            for i, j in pairs:\n",
    "                center = (i + j) / 2\n",
    "                width = abs(j - i)\n",
    "                height = width / 5  # Adjust for aesthetics\n",
    "                ax.add_patch(plt.Rectangle((center - width/2, 0), width, height, \n",
    "                             facecolor='none', edgecolor='blue', alpha=0.5, \n",
    "                             transform=ax.transData.skewed(0, 0, 1, 0)))\n",
    "            \n",
    "            ax.set_title(f\"RNA Structure for {example_target}\")\n",
    "            ax.set_xlim(-1, len(structure) + 1)\n",
    "            ax.set_ylim(-0.5, (len(structure)/10) + 1)\n",
    "            ax.set_yticks([])\n",
    "            ax.set_xticks(range(0, len(structure), 10))\n",
    "            plt.show()\n",
    "        \n",
    "        # Plot positional entropy if available\n",
    "        if 'position_entropy' in thermo:\n",
    "            entropy = thermo['position_entropy']\n",
    "            \n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.plot(range(len(entropy)), entropy, 'b-')\n",
    "            plt.title(f\"Positional Entropy for {example_target}\")\n",
    "            plt.xlabel(\"Position\")\n",
    "            plt.ylabel(\"Entropy\")\n",
    "            plt.grid(alpha=0.3)\n",
    "            plt.show()\n",
    "    \n",
    "    # Visualize MI features if available\n",
    "    if 'mi' in features:\n",
    "        mi = features['mi']\n",
    "        print(\"\\nMI features:\")\n",
    "        \n",
    "        # Print top pairs if available\n",
    "        if 'top_pairs' in mi and len(mi['top_pairs']) > 0:\n",
    "            top_pairs = mi['top_pairs']\n",
    "            print(f\"  Top 5 MI pairs:\")\n",
    "            for i in range(min(5, len(top_pairs))):\n",
    "                pair = top_pairs[i]\n",
    "                print(f\"    {pair[0]} - {pair[1]}: {pair[2]:.4f}\")\n",
    "        \n",
    "        # Plot MI matrix if available\n",
    "        if 'scores' in mi:\n",
    "            scores = mi['scores']\n",
    "            \n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.imshow(scores, cmap='viridis', origin='lower')\n",
    "            plt.colorbar(label='Mutual Information')\n",
    "            plt.title(f\"Mutual Information Matrix for {example_target}\")\n",
    "            plt.xlabel(\"Position\")\n",
    "            plt.ylabel(\"Position\")\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"No targets available for visualization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rna3d-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
